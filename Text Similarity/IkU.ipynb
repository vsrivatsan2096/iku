{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3hUGck-ksJp"
   },
   "source": [
    "# Semantics Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LPXZlsook9cd"
   },
   "source": [
    "**Installing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqGfhdAakih2"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q numpy\n",
    "!pip install -U -q keras\n",
    "!pip install -U -q scikit-learn\n",
    "!pip install -U -q matplotlib\n",
    "!pip install -U -q nltk\n",
    "!pip install -U -q PyDrive \n",
    "!pip install -U -q pandas\n",
    "!pip3 install --quiet tensorflow-hub\n",
    "!pip3 install --quiet seaborn\n",
    "!pip3 install --quiet \"tensorflow>=1.7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "016VNjCml2NW"
   },
   "source": [
    "**Getting data from Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TEWzFSplqVP"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSqhf7dHl_SS"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MqJZtt-HmF6v"
   },
   "outputs": [],
   "source": [
    "file_ids = [\"16-aKOfyeLQpBJlUHCJUGxWp4UsY2rvb3\", \"1oec77bHzg5a2oGshDuBe99jxMi80NlUo\"]\n",
    "file_names = [\"train_translated.csv\", \"test_translated.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLtygnFNmLx_"
   },
   "outputs": [],
   "source": [
    "for each_id, each_name in zip(file_ids, file_names):\n",
    "    download = drive.CreateFile({'id':each_id})\n",
    "    download.GetContentFile(each_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNPMenzA0Yyj"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3Z7qyzq0g6Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Asu7UheH2GU3",
    "outputId": "c7a5f262-2342-40ee-f165-5e1b97bd75c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 102: expected 5 fields, saw 6\\nSkipping line 656: expected 5 fields, saw 6\\nSkipping line 867: expected 5 fields, saw 6\\nSkipping line 880: expected 5 fields, saw 6\\nSkipping line 980: expected 5 fields, saw 6\\nSkipping line 1439: expected 5 fields, saw 6\\nSkipping line 1473: expected 5 fields, saw 6\\nSkipping line 1822: expected 5 fields, saw 6\\nSkipping line 1952: expected 5 fields, saw 6\\nSkipping line 2009: expected 5 fields, saw 6\\nSkipping line 2230: expected 5 fields, saw 6\\nSkipping line 2506: expected 5 fields, saw 6\\nSkipping line 2523: expected 5 fields, saw 6\\nSkipping line 2809: expected 5 fields, saw 6\\nSkipping line 2887: expected 5 fields, saw 6\\nSkipping line 2920: expected 5 fields, saw 6\\nSkipping line 2944: expected 5 fields, saw 6\\nSkipping line 3241: expected 5 fields, saw 6\\nSkipping line 3358: expected 5 fields, saw 6\\nSkipping line 3459: expected 5 fields, saw 6\\n'\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"E:\\Datasets\\microsoft\\msr-para-train.tsv\", sep='\\t', error_bad_lines=False, skip_blank_lines=True, keep_default_na=False)\n",
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_Anv5AYHe5X"
   },
   "outputs": [],
   "source": [
    "test1 = test.iloc[:, 3].values\n",
    "test2 = test.iloc[:, 4].values\n",
    "res = test.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv(\"E:\\Datasets\\quora\\questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions1 = questions.iloc[:, 3].values\n",
    "questions2 = questions.iloc[:, 4].values\n",
    "is_duplicate_questions = questions.iloc[:, 5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjk1awi9vns5"
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNVsrA9WHe5b"
   },
   "outputs": [],
   "source": [
    "length = res.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_p_l_rms_l_1 = questions1\n",
    "dataset_p_l_rms_l_2 = questions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7q4ZLpcKj0v"
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsMTUtGdKoJM"
   },
   "source": [
    "**Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TEybJIOKkgT"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "uRnXzsycKsMg",
    "outputId": "8b41cc96-5296-44c5-ca5a-9d62266da722",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vsriv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vsriv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTPkxZdiK0BD"
   },
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "stopword = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rd75AVttK7hD"
   },
   "outputs": [],
   "source": [
    "dataset_p_l_rms_l_1 = []\n",
    "dataset_p_l_rms_1 = []\n",
    "for i in questions1:\n",
    "    tempx = re.sub(r\"[^A-Za-z]\", \" \", str(i))\n",
    "    tempx = tempx.lower().split()\n",
    "    tempx = [word for word in tempx if word not in stopword]\n",
    "    dataset_p_l_rms_1.append(\" \".join(tempx))\n",
    "    tempx = [lemma.lemmatize(word, pos=\"a\") for word in tempx]\n",
    "    tempx = [lemma.lemmatize(word, pos=\"r\") for word in tempx]\n",
    "    tempx = [lemma.lemmatize(word, pos=\"n\") for word in tempx]\n",
    "    tempx = [lemma.lemmatize(word, pos=\"v\") for word in tempx]\n",
    "    dataset_p_l_rms_l_1.append(\" \".join(tempx))\n",
    "dataset_p_l_rms_l_1 = np.asarray(dataset_p_l_rms_l_1)\n",
    "dataset_p_l_rms_1 = np.asarray(dataset_p_l_rms_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdAWSHcJHe5q"
   },
   "outputs": [],
   "source": [
    "dataset_p_l_rms_l_2 = []\n",
    "dataset_p_l_rms_2 = []\n",
    "for i in questions2:\n",
    "    tempx = re.sub(r\"[^A-Za-z]\", \" \", str(i))\n",
    "    tempx = tempx.lower().split()\n",
    "    tempx = [word for word in tempx if word not in stopword]\n",
    "    dataset_p_l_rms_2.append(\" \".join(tempx))\n",
    "    tempx = [lemma.lemmatize(word, pos=\"a\") for word in tempx]\n",
    "    tempx = [lemma.lemmatize(word, pos=\"r\") for word in tempx]\n",
    "    tempx = [lemma.lemmatize(word, pos=\"n\") for word in tempx]\n",
    "    tempx = [lemma.lemmatize(word, pos=\"v\") for word in tempx]\n",
    "    dataset_p_l_rms_l_2.append(\" \".join(tempx))\n",
    "dataset_p_l_rms_l_2 = np.asarray(dataset_p_l_rms_l_2)\n",
    "dataset_p_l_rms_2 = np.asarray(dataset_p_l_rms_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astrology capricorn sun cap moon cap rising say\n",
      "triple capricorn sun moon ascendant capricorn say\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "dataset_no = 5\n",
    "print(dataset_p_l_rms_1[dataset_no])\n",
    "print(dataset_p_l_rms_2[dataset_no])\n",
    "print(is_duplicate_questions[dataset_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    }
   ],
   "source": [
    "max_words = 0\n",
    "for each in dataset_p_l_rms_l_1:\n",
    "    max_words = max(len(each.split()), max_words)\n",
    "\n",
    "for each in dataset_p_l_rms_l_2:\n",
    "    max_words = max(len(each.split()), max_words)\n",
    "print(max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Comparisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Vectorizor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(np.append(dataset_p_l_rms_l_1, dataset_p_l_rms_l_2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_dataset_p_l_rms_l_1 = count_vectorizer.transform(dataset_p_l_rms_l_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_dataset_p_l_rms_l_2 = count_vectorizer.transform(dataset_p_l_rms_l_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_similarity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-3555e14a376c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_duplicate_questions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mquestions_similarity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_dataset_p_l_rms_l_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_dataset_p_l_rms_l_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[1;32m--> 905\u001b[1;33m                         dense_output=dense_output)\n\u001b[0m\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \"\"\"\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"toarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[0mmajor_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# convert to this format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         idx_dtype = get_index_dtype((self.indptr, self.indices,\n",
      "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[0marg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36masformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;31m# Forward the copy kwarg, if it's accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\sparse\\csc.py\u001b[0m in \u001b[0;36mtocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    149\u001b[0m                   \u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                   \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m                   data)\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0, len(is_duplicate_questions)):    \n",
    "    questions_similarity.append(cosine_similarity(v_dataset_p_l_rms_l_1[i], v_dataset_p_l_rms_l_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    print(is_duplicate_questions[i], questions_similarity[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tfidf Vectorizor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer.fit(np.append(train, test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train = tfidf_vectorizer.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_test = tfidf_vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-xcGFtPGdfJ"
   },
   "source": [
    "**LSA Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYXzCvrQGgm3"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHMV-1Bhai1e"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DObvs6mal97"
   },
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=300,\n",
    "                         algorithm='randomized',\n",
    "                         n_iter=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__L-nT-lapFP"
   },
   "outputs": [],
   "source": [
    "lsa_model1 = Pipeline([('tfidf', vectorizer), \n",
    "                            ('svd', svd_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cCFrhTD-He55"
   },
   "outputs": [],
   "source": [
    "lsa_model2 = Pipeline([('tfidf', vectorizer), \n",
    "                            ('svd', svd_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0Qm7cU-asMM"
   },
   "outputs": [],
   "source": [
    "lsa_test1 = lsa_model1.fit_transform(dataset_p_l_rms_l_1)\n",
    "lsa_test2 = lsa_model2.fit_transform(dataset_p_l_rms_l_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShsDeBj0He59"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-RqCVPvHe5_"
   },
   "outputs": [],
   "source": [
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHVZTTRYHe6A",
    "outputId": "cc91ef3d-720c-4269-f4f8-c6729caa3889"
   },
   "outputs": [],
   "source": [
    "founded_lsa = []\n",
    "for i in range(lsa_test1.shape[0]):\n",
    "    temp = cosine(lsa_test1[i], lsa_test2[i])\n",
    "    if not isnan(temp):\n",
    "        founded_lsa.append(1 - int(temp))\n",
    "    else:\n",
    "        founded_lsa.append(0)\n",
    "founded_lsa = np.asarray(founded_lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uENvSaywLgrP"
   },
   "source": [
    "**Word2Vec model(Using Mean to get the sentence vectors)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_vSYQP8LN36"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61vPjXTNB8Ur"
   },
   "outputs": [],
   "source": [
    "wiki_model = KeyedVectors.load_word2vec_format(\"models/pretrained/glove/wiki/wiki.300d.txt\", binary=False)\n",
    "#google_model = KeyedVectors.load_word2vec_format(\"models/pretrained/word2vec/google/google.300d.bin\", binary=True)\n",
    "#common_crawl_model = KeyedVectors.load_word2vec_format(\"models/pretrained/glove/common_crawl/common_crawl.300d.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOUcqYwzLzTf"
   },
   "outputs": [],
   "source": [
    "def sentence_vectorizer(model, sentence):\n",
    "    vectors =[]\n",
    "    num = 0\n",
    "    for i in sentence.split():\n",
    "        try:\n",
    "            if num == 0:\n",
    "                vectors = model[i]\n",
    "            else:\n",
    "                vectors = np.add(vectors, model[i])\n",
    "            num += 1\n",
    "        except:\n",
    "            pass\n",
    "    return np.array(vectors) / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsR-G4WYsu70"
   },
   "outputs": [],
   "source": [
    "sent_vec1 = []\n",
    "for each in dataset_p_l_rms_1:\n",
    "    temp = sentence_vectorizer(google_model, each)\n",
    "    if temp.shape[0] != 0:\n",
    "        sent_vec1.append(temp)\n",
    "    else:\n",
    "        sent_vec1.append(np.zeros((300,)))\n",
    "sent_vec1 = np.asarray(sent_vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4EsdRpmHGhpM"
   },
   "outputs": [],
   "source": [
    "sent_vec2 = []\n",
    "for each in dataset_p_l_rms_2:\n",
    "    temp = sentence_vectorizer(google_model, each)\n",
    "    if temp.shape[0] != 0:\n",
    "        sent_vec2.append(temp)\n",
    "    else:\n",
    "        sent_vec2.append(np.zeros((300,)))\n",
    "sent_vec2 = np.asarray(sent_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STeo9-I-He6R"
   },
   "outputs": [],
   "source": [
    "founded_sent2vec = []\n",
    "for i in range(length):\n",
    "    temp = cosine(sent_vec1[i], sent_vec2[i])\n",
    "    if not isnan(temp):\n",
    "        founded_sent2vec.append(1 - int(temp))\n",
    "    else:\n",
    "        founded_sent2vec.append(0)\n",
    "founded_sent2vec = np.asarray(founded_sent2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sent2Vec model(Fast.ai)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/epfml/sent2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Doc2Vec Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sentence Encoder V2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"Elephant\"\n",
    "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
    "paragraph = (\n",
    "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
    "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
    "    \"the more 'diluted' the embedding will be.\")\n",
    "messages = [word, sentence, paragraph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    message_embeddings = session.run(embed(messages))\n",
    "    for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "        print(\"Message: {}\".format(messages[i]))\n",
    "        print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "        message_embedding_snippet = \", \".join(\n",
    "            (str(x) for x in message_embedding[:3]))\n",
    "        print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation):\n",
    "    corr = np.inner(features, features)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(\n",
    "        corr,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(labels, rotation=rotation)\n",
    "    g.set_title(\"Semantic Textual Similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_plot(session_, input_tensor_, messages_, encoding_tensor):\n",
    "    message_embeddings_ = session_.run(\n",
    "        encoding_tensor, feed_dict={input_tensor_: messages_})\n",
    "    plot_similarity(messages_, message_embeddings_, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    \"I am an Indian\",\n",
    "    \"I am from India\",\n",
    "    \"I am not from India\",\n",
    "    \"I play cricket\",\n",
    "    \"I watch television\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
    "similarity_message_encodings = embed(similarity_input_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    run_and_plot(session, similarity_input_placeholder, messages,\n",
    "         similarity_message_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elQTFbMuHhgN"
   },
   "source": [
    "**Siamese Neural Networks(Using LSTM and GRU)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/mlreview/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2639,
     "status": "ok",
     "timestamp": 1549095603688,
     "user": {
      "displayName": "Sri Vatsan",
      "photoUrl": "",
      "userId": "12441326585716590406"
     },
     "user_tz": -330
    },
    "id": "dE_9Xb7uHqgw",
    "outputId": "84a6f14b-0c50-4bb8-d8f5-b431d981f11b"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import keras.backend as backend\n",
    "from keras.layers import Input, Embedding, LSTM, Lambda, GRU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(test1) + 1, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden1 = 512\n",
    "n_hidden2 = 384\n",
    "n_hidden3 = 256\n",
    "n_hidden4 = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WljRtYIvJcTn"
   },
   "outputs": [],
   "source": [
    "left_input = Input(shape=(max_words, ), dtype='int32')\n",
    "right_input = Input(shape=(max_words, ), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksWe8MukKbxW"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], \n",
    "                            input_length=max_words, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0jTBGv4Kck8"
   },
   "outputs": [],
   "source": [
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5e9B1ChNKgA3"
   },
   "outputs": [],
   "source": [
    "shared_lstm1 = LSTM(n_hidden1, return_sequences=True)\n",
    "shared_dropout1 = Dropout(0.3)\n",
    "shared_gru1 = GRU(n_hidden2, return_sequences=True)\n",
    "shared_dropout2 = Dropout(0.4)\n",
    "shared_gru2 = GRU(n_hidden3, return_sequences=True)\n",
    "shared_dropout3 = Dropout(0.3)\n",
    "shared_lstm2 = LSTM(n_hidden4, return_sequences=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oiSpiz9uLGu3"
   },
   "outputs": [],
   "source": [
    "left_lstm1 = shared_lstm1(encoded_left)\n",
    "left_dropout1 = shared_dropout1(left_lstm1)\n",
    "left_gru1 = shared_gru1(left_dropout1)\n",
    "left_dropout2 = shared_dropout2(left_gru1)\n",
    "left_gru2 = shared_gru2(left_dropout2)\n",
    "left_dropout3 = shared_dropout3(left_gru2)\n",
    "left_lstm2 = shared_lstm2(left_dropout3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcQJfYn6Ma5S"
   },
   "outputs": [],
   "source": [
    "right_lstm1 = shared_lstm1(encoded_right)\n",
    "right_dropout1 = shared_dropout1(right_lstm1)\n",
    "right_gru1 = shared_gru1(right_dropout1)\n",
    "right_dropout2 = shared_dropout2(right_gru1)\n",
    "right_gru2 = shared_gru2(right_dropout2)\n",
    "right_dropout3 = shared_dropout3(right_gru2)\n",
    "right_lstm2 = shared_lstm2(right_dropout3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ug1R5gTGM4oR"
   },
   "outputs": [],
   "source": [
    "manhattan_distance_for_lstm = Lambda(function=lambda x: backend.exp(-backend.sum(backend.abs(x[0]-x[1]), axis=1, keepdims=True)),\n",
    "                                     output_shape=lambda x: (x[0][0], 1))([left_lstm2, right_lstm2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3dWiDq3dUK7m"
   },
   "source": [
    "**Training and Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fkjFhAkT8Ov"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNlq-mXyUjO9"
   },
   "outputs": [],
   "source": [
    "stratkfold = StratifiedKFold(n_splits=2, random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5TGTK2CUrN8"
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in stratkfold.split(test1, res):\n",
    "    siamese_network = Model([left_input, right_input], manhattan_distance_for_lstm)\n",
    "    siamese_network.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    siamese_network.fit([test1[train_index], test2[train_index]], res[train_index], batch_size=128, \n",
    "                        epochs=128, validation_data=([test1[test_index], test2[test_index]], res[test_index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Erk3iRTcW9Lb"
   },
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SqSI60RXDd2"
   },
   "outputs": [],
   "source": [
    "siamese_network = Model([left_input, right_input], manhattan_distance_for_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gumorqrYXDOS"
   },
   "outputs": [],
   "source": [
    "siamese_network.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WSGBgGwXC_R"
   },
   "outputs": [],
   "source": [
    "siamese_network.fit([test1[train_index], test2[train_index]], res[train_index], batch_size=128, epochs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGyxnRuCHe6T"
   },
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8U9QUzGUHe6U"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Em0idSRBHe6V"
   },
   "source": [
    "**LSA Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5x_Xej09He6W",
    "outputId": "fc2d20a4-3cae-4cc5-e2e3-df4a68825d53"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score :\", accuracy_score(is_duplicate_questions, founded_lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyzrfpRWHe6Y",
    "outputId": "36ee63ac-6c07-491c-8cab-02411ba57d93"
   },
   "outputs": [],
   "source": [
    "print(\"Precision :\", precision_score(is_duplicate_questions, founded_lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_7dXh_gHe6a",
    "outputId": "34f22ea6-6364-4458-b44b-f03d32ebe9ad"
   },
   "outputs": [],
   "source": [
    "print(\"Recall Score :\", recall_score(is_duplicate_questions, founded_lsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAcIrkueHe6d",
    "outputId": "b7109c07-77ea-4111-c841-cc0c5276cdf3"
   },
   "outputs": [],
   "source": [
    "print(\"F1 Score :\", f1_score(is_duplicate_questions, founded_lsa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6qjSGvAHe6f"
   },
   "source": [
    "**Sentence2Vec(Modified word2vec) Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8263tpeHe6h",
    "outputId": "bacfcf86-1d83-45a6-98db-ed325c5e5bb5"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score :\", accuracy_score(res, founded_sent2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWthDUYRHe6k",
    "outputId": "8ffab08e-7e47-49fb-8eaf-6c1566061948"
   },
   "outputs": [],
   "source": [
    "print(\"Precision :\", precision_score(res, founded_sent2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aEKGf4lgHe6m",
    "outputId": "ef8472e3-d3dc-43ce-a480-e108f601bc22"
   },
   "outputs": [],
   "source": [
    "print(\"Recall :\", recall_score(res, founded_sent2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRLQnmzoHe6r",
    "outputId": "1d54178c-89ed-4fd0-aa31-eb01dd8fe3c3"
   },
   "outputs": [],
   "source": [
    "print(\"F1 Score :\", f1_score(res, founded_sent2vec))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Semantics_Similarity.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
