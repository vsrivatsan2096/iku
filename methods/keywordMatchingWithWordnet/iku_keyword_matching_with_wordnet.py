# -*- coding: utf-8 -*-
"""Iku-Keyword matching with wordnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zog7hBNitrL39PFds-WQwZL3sRAlf2Vo

# Keyword Matching with Wordnet

**`Importing packages`**
"""

import nltk
nltk.download('wordnet')
from nltk.corpus import wordnet as wn
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances

"""**Setting up answer keys**"""

answer_keys = []


answer_keys.append({
    'question_no' : 1,
    'answer' : ["the principle that the speed and capability of computers can be expected to double every two years, as a result of increases in the number of transistors a microchip can contain"],
    'exact' : True,
    'type' : "keyword",
    'keywords': {
        'total_score' : 1,
        'words' : ['speed','double','two'],
        'words_score'  : [0.5,0.75,0.75]
    }
})


answer_keys.append({
    'question_no' : 2,
    'answer' : ["the natural agent that stimulates sight and makes things visible"],
    'exact' : False,
    'type' : "keyword",
    'keywords': {
        'total_score' : 1,
        'words' : ["natural", "visible"],
        'words_score'  : [0.5, 0.5]
    }
})

"""**Setting Up Student Answer**"""

students_answers = []

students_answers.append({
    "student_id": 1,
    "answers"   : [{
        "question_no" : 1,
        "answer"      : ["the principle that the speed and capability of computers can be expected to double every two years, as a result of increases in the number of transistors a microchip can contain"]
    },{
        "question_no" : 2,
        "answer"       :["the natural agent that stimulates sight and makes things visible"]
    }]
})
        
  
students_answers.append({
    "student_id": 2,
    "answers"   : [{
        "question_no" : 1,
        "answer"      : ["the principle that the pace and capability of computers can be expected to double every two years"]
    },{
        "question_no" : 2,
        "answer"      :["the natural agent that stimulates sight"]
    }]
})

answers_length = len(answer_keys)
print(students_answers[current_answer]["answers"][0]['answer'])

"""**Different Methods of Evaluation**"""

meta_scores = []

"""**Exact match**"""

def keyword_similarity(answer_key, answer):
    if answer_key["question_no"] != answer["question_no"]:
         assert("Question No does not match")
    score = 0
    for keyword_index in range(len(answer_key['keywords']['words'])):
        if answer_key['keywords']['words'][keyword_index] in answer['answer'][0]:
            score += answer_key['keywords']['words_score'][keyword_index] * answer_key['keywords']['total_score']
    return score

"""**Semantically similar Keyword**"""

def keyword_similarity_concept(answer_key, answer):
    if answer_key["question_no"] != answer["question_no"]:
         assert("Question No does not match")
    score = 0
    for keyword_index in range(len(answer_key['keywords']['words'])):
        if synonymous_in_some_way(  answer_key['keywords']['words'][keyword_index], answer['answer'][0]):
            score += answer_key['keywords']['words_score'][keyword_index] * answer_key['keywords']['total_score']
    return score

"""**Checking across possible synonyms**"""

def synonymous_in_some_way(keywords,answer):
 
  print ("answer")
  print(answer)
  keyword_syn= wn.synsets(keywords)
  answer_arr= answer.split(" ")
  
  for answer_word in answer_arr:
    current_syn= wn.synsets(answer_word)
    
    for similar_keywords in keyword_syn:
      for similar_answers in current_syn:
        if not similar_keywords.wup_similarity(similar_answers)==None and similar_keywords.wup_similarity(similar_answers)>0.9:
          return True
        
  return False

"""**Perform check for analysis**"""

for index in range(answers_length):
    temp_meta_score = []
    print ("index no.")
    print (index)
    
    for current_answer in range( len(students_answers)):
      if answer_keys[index]['exact'] and answer_keys[index]['type'] == "law":
          count_vectorizer = CountVectorizer()
          count_vectorizer.fit(answer_keys[index]['answer'] + students_answers[current_answer]["answers"][index]['answer'])
          x = count_vectorizer.transform(answer_keys[index]['answer'])
          y = count_vectorizer.transform(students_answers[current_answer]["answers"][0]["answer"])
          meta_scores.append({
          "Euclidean Distance" : euclidean_distances(x, y).ravel()[0],
          "Manhattan Distance" : manhattan_distances(x, y).ravel()[0]
          })

      elif answer_keys[index]['exact'] and answer_keys[index]['type'] == "keyword":
        
          meta_scores.append({
          "Keyword Similariy": keyword_similarity_exact(answer_keys[index], students_answers[current_answer]["answers"][index])})
          print ("mytime")

      elif not answer_keys[index]['exact'] and answer_keys[index]['type'] == "keyword":
          meta_scores.append({
          "Keyword Similariy": keyword_similarity_concept(answer_keys[index], students_answers[current_answer]["answers"][index])})
          print("Exectued")

"""**Printing Results**"""

print(meta_scores)