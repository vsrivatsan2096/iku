{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IkU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "U3hUGck-ksJp"
      },
      "cell_type": "markdown",
      "source": [
        "# Semantics Similarity"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LPXZlsook9cd"
      },
      "cell_type": "markdown",
      "source": [
        "**Installing the Libraries**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AqGfhdAakih2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q numpy\n",
        "!pip install -U -q keras\n",
        "!pip install -U -q scikit-learn\n",
        "!pip install -U -q matplotlib\n",
        "!pip install -U -q nltk\n",
        "!pip install -U -q PyDrive \n",
        "!pip install -U -q pandas\n",
        "!pip install -U -q https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-win_amd64.whl\n",
        "!pip install -U -q torchvision\n",
        "!pip install --quiet tensorflow-hub\n",
        "!pip install --quiet seaborn\n",
        "!pip install --quiet \"tensorflow>=1.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "016VNjCml2NW"
      },
      "cell_type": "markdown",
      "source": [
        "**Getting data from Google Drive**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3TEWzFSplqVP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GSqhf7dHl_SS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MqJZtt-HmF6v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_ids = [\"16-aKOfyeLQpBJlUHCJUGxWp4UsY2rvb3\", \"1oec77bHzg5a2oGshDuBe99jxMi80NlUo\"]\n",
        "file_names = [\"train_translated.csv\", \"test_translated.csv\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nLtygnFNmLx_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for each_id, each_name in zip(file_ids, file_names):\n",
        "    download = drive.CreateFile({'id':each_id})\n",
        "    download.GetContentFile(each_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HNPMenzA0Yyj"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "J3Z7qyzq0g6Q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bM1togrSTgrm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "questions = pd.read_csv(\"E:\\Datasets\\quora\\questions.csv\")\n",
        "questions.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N3hpXv-GTgup",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "questions1 = questions.iloc[:, 3].values\n",
        "questions2 = questions.iloc[:, 4].values\n",
        "is_duplicate_questions = questions.iloc[:, 5].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nVTLX122TgyM",
        "colab_type": "code",
        "outputId": "93000205-085a-4765-9596-5a61b1b5c240",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "questions.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sjk1awi9vns5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mNVsrA9WHe5b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "length = is_duplicate_questions.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "k7q4ZLpcKj0v"
      },
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VsMTUtGdKoJM"
      },
      "cell_type": "markdown",
      "source": [
        "**Text Preprocessing**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3TEybJIOKkgT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.utils import simple_preprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uRnXzsycKsMg",
        "outputId": "8b41cc96-5296-44c5-ca5a-9d62266da722",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\vsriv\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\vsriv\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\vsriv\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KTPkxZdiK0BD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lemma = WordNetLemmatizer()\n",
        "stopword = stopwords.words(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rd75AVttK7hD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences_1 = []\n",
        "for i in questions1:\n",
        "    tempx = re.sub(r\"[^A-Za-z]\", \" \", str(i))\n",
        "    tempx = tempx.lower().split()\n",
        "    tempx = [word for word in tempx if word not in stopword]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"a\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"r\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"n\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"v\") for word in tempx]\n",
        "    sentences_1.append(\" \".join(tempx))\n",
        "sentences_1 = np.asarray(sentences_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HdAWSHcJHe5q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences_2 = []\n",
        "for i in questions2:\n",
        "    tempx = re.sub(r\"[^A-Za-z]\", \" \", str(i))\n",
        "    tempx = tempx.lower().split()\n",
        "    tempx = [word for word in tempx if word not in stopword]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"a\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"r\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"n\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"v\") for word in tempx]\n",
        "    sentences_2.append(\" \".join(tempx))\n",
        "sentences_2 = np.asarray(sentences_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fKX7KgO2ThOF",
        "colab_type": "code",
        "outputId": "78d76762-1ff6-4530-fa10-359ce29ab4dd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_no = 5\n",
        "print(sentences_1[dataset_no])\n",
        "print(sentences_2[dataset_no])\n",
        "print(is_duplicate_questions[dataset_no])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "astrology capricorn sun cap moon cap rise say\n",
            "triple capricorn sun moon ascendant capricorn say\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vexhv8koThUG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text Comparisions"
      ]
    },
    {
      "metadata": {
        "id": "2HfIFP2nThU5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Count Vectorizor**"
      ]
    },
    {
      "metadata": {
        "id": "_EG7A4_5ThU-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UZAd3cLmThVH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ju8VDbbThVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count_vectorizer.fit(np.append(sentences_1, sentences_2, axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdhWUchuThV0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count_vectorizer_1 = count_vectorizer.transform(sentences_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xyA2jAqThWI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "count_vectorizer_2 = count_vectorizer.transform(sentences_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qGNzheIkThWw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kp_nZsiYThXp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KUmkDuPtThX_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    temp = {}\n",
        "    temp['cosine_similarity'] = cosine_similarity(count_vectorizer_1[i], count_vectorizer_2[i])[0][0]\n",
        "    temp['manhattan_distance'] = euclidean_distances(count_vectorizer_1[i], count_vectorizer_2[i])[0][0]\n",
        "    temp['euclidean_distance'] = manhattan_distances(count_vectorizer_1[i], count_vectorizer_2[i])[0][0]\n",
        "    distance_and_similarity_scores.append(temp)\n",
        "#try to give this to log reg to find the similarity between these data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5Y-SmyuThYX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    print(is_duplicate_questions[i], distance_and_similarity_scores[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "96lHm_K7ThYo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tfidf Vectorizor**"
      ]
    },
    {
      "metadata": {
        "id": "bclx9esnThYt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YMfi9YTThY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z-YXH_xvThZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer.fit(np.append(sentences_1, sentences_2, axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZYiy4BIThZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfid_vectorizer_1 = tfidf_vectorizer.transform(sentences_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PkMvn_jpThZ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfid_vectorizer_2 = tfidf_vectorizer.transform(sentences_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wb-ei7nEThaU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores_2 = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "opr1Y6dkThay",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    temp = {}\n",
        "    temp['cosine_similarity'] = cosine_similarity(tfid_vectorizer_1[i], tfid_vectorizer_2[i])[0][0]\n",
        "    temp['manhattan_distance'] = euclidean_distances(tfid_vectorizer_1[i], tfid_vectorizer_2[i])[0][0]\n",
        "    temp['euclidean_distance'] = manhattan_distances(tfid_vectorizer_1[i], tfid_vectorizer_2[i])[0][0]\n",
        "    distance_and_similarity_scores_2.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UYT884iPThbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    print(is_duplicate_questions[i], distance_and_similarity_scores_2[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "w-xcGFtPGdfJ"
      },
      "cell_type": "markdown",
      "source": [
        "**LSA Method**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jYXzCvrQGgm3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LHMV-1Bhai1e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2DObvs6mal97",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "svd_model = TruncatedSVD(n_components=300,\n",
        "                         algorithm='randomized',\n",
        "                         n_iter=10, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "__L-nT-lapFP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsa_model1 = Pipeline([('tfidf', vectorizer), \n",
        "                            ('svd', svd_model)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cCFrhTD-He55",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsa_model2 = Pipeline([('tfidf', vectorizer), \n",
        "                            ('svd', svd_model)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d0Qm7cU-asMM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsa_1 = lsa_model1.fit_transform(sentences_1)\n",
        "lsa_2 = lsa_model2.fit_transform(sentences_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ShsDeBj0He59",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores_3 = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t-RqCVPvHe5_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    temp = {}\n",
        "    temp['cosine_similarity'] = cosine_similarity(np.asarray([lsa_1[i]]), np.asarray([lsa_2[i]]))[0][0]\n",
        "    temp['manhattan_distance'] = euclidean_distances(np.asarray([lsa_1[i]]), np.asarray([lsa_2[i]]))[0][0]\n",
        "    temp['euclidean_distance'] = manhattan_distances(np.asarray([lsa_1[i]]), np.asarray([lsa_2[i]]))[0][0]\n",
        "    distance_and_similarity_scores_3.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jHVZTTRYHe6A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    print(is_duplicate_questions[i], distance_and_similarity_scores_3[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uENvSaywLgrP"
      },
      "cell_type": "markdown",
      "source": [
        "**Word2Vec model(Using Mean to get the sentence vectors)**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "n_vSYQP8LN36",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "61vPjXTNB8Ur",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "google_model = KeyedVectors.load_word2vec_format(\"E:\\Models\\pre_trained\\word2vec\\google\\google.300d.bin\", binary=True)\n",
        "#wiki_model = KeyedVectors.load_word2vec_format(\"models/pretrained/glove/wiki/wiki.300d.txt\", binary=False)\n",
        "#common_crawl_model = KeyedVectors.load_word2vec_format(\"models/pretrained/glove/common_crawl/common_crawl.300d.txt\", binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tOUcqYwzLzTf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sentence_vectorizer(model, sentence):\n",
        "    vectors =[]\n",
        "    num = 0\n",
        "    for i in sentence.split():\n",
        "        try:\n",
        "            if num == 0:\n",
        "                vectors = model[i]\n",
        "            else:\n",
        "                vectors = np.add(vectors, model[i])\n",
        "            num += 1\n",
        "        except:\n",
        "            pass\n",
        "    return np.array(vectors) / num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xsR-G4WYsu70",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec1 = []\n",
        "for each in sentences_1:\n",
        "    temp = sentence_vectorizer(google_model, each)\n",
        "    if temp.shape[0] != 0:\n",
        "        sent_vec1.append(temp)\n",
        "    else:\n",
        "        sent_vec1.append(np.zeros((300,)))\n",
        "sent_vec1 = np.asarray(sent_vec1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4EsdRpmHGhpM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec2 = []\n",
        "for each in sentences_2:\n",
        "    temp = sentence_vectorizer(google_model, each)\n",
        "    if temp.shape[0] != 0:\n",
        "        sent_vec2.append(temp)\n",
        "    else:\n",
        "        sent_vec2.append(np.zeros((300,)))\n",
        "sent_vec2 = np.asarray(sent_vec2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "STeo9-I-He6R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores_4 = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WhWO60WThjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    temp = {}\n",
        "    temp['cosine_similarity'] = cosine_similarity(np.asarray([sent_vec1[i]]), np.asarray([sent_vec2[i]]))[0][0]\n",
        "    temp['manhattan_distance'] = euclidean_distances(np.asarray([sent_vec1[i]]), np.asarray([sent_vec2[i]]))[0][0]\n",
        "    temp['euclidean_distance'] = manhattan_distances(np.asarray([sent_vec1[i]]), np.asarray([sent_vec2[i]]))[0][0]\n",
        "    distance_and_similarity_scores_4.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNWdkvV0Thjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    print(is_duplicate_questions[i], distance_and_similarity_scores_4[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wzvLAyArThkL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Doc2Vec Model**"
      ]
    },
    {
      "metadata": {
        "id": "4qn_RcTXThkP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Abisek Update this and use quora questions dataset"
      ]
    },
    {
      "metadata": {
        "id": "NPFU-WBzThkS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**InferText model**"
      ]
    },
    {
      "metadata": {
        "id": "GjDUVOyGThkU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://github.com/facebookresearch/InferSent"
      ]
    },
    {
      "metadata": {
        "id": "6dv_PWSvThkV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "josZK7nlThkw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load Model"
      ]
    },
    {
      "metadata": {
        "id": "n6zpFS63Thk-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from models.infersent.models import InferSent\n",
        "model_version = 1\n",
        "MODEL_PATH = \"models\\infersent\\infersent%s.pickle\" % model_version\n",
        "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
        "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
        "model = InferSent(params_model)\n",
        "model.load_state_dict(torch.load(MODEL_PATH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3Ab2lSGThlU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "use_cuda = False\n",
        "model = model.cuda() if use_cuda else model # Keep it on CPU or put it on GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGK1B7e0ThlZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W2V_PATH = 'E:\\Models\\pre_trained\\glove\\commoncrawl\\common_crawl.300d.txt'\n",
        "model.set_w2v_path(W2V_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Wpz7wfJThld",
        "colab_type": "code",
        "outputId": "6252e255-9111-4e78-8859-ca21ed066c1a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.build_vocab_k_words(K=100000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1llZQxTQThme",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Encode Sentences"
      ]
    },
    {
      "metadata": {
        "id": "p28QtnCsThmi",
        "colab_type": "code",
        "outputId": "d02b0ca6-47e1-4f8d-ef39-c9abd2e23059",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "tW3EZmx8Thm3",
        "colab_type": "code",
        "outputId": "ce05dcb8-0200-4418-f38e-57f9ffec7a9a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_1 = model.encode(sentences_1[:20], bsize=128, tokenize=False, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nb words kept : 139/152 (91.4%)\n",
            "Speed : 25.0 sentences/s (cpu mode, bsize=128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GWaFFXssThnW",
        "colab_type": "code",
        "outputId": "8fb52c07-47ec-46f2-a51f-09a2ff559c75",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_2 = model.encode(sentences_2[:20], bsize=128, tokenize=False, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nb words kept : 140/150 (93.3%)\n",
            "Speed : 35.7 sentences/s (cpu mode, bsize=128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OALLFIe_Thne",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores_6 = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVMyyBHmThnk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    temp = {}\n",
        "    temp['cosine_similarity'] = cosine_similarity(np.asarray([embeddings_1[i]]), np.asarray([embeddings_2[i]]))[0][0]\n",
        "    temp['manhattan_distance'] = euclidean_distances(np.asarray([embeddings_1[i]]), np.asarray([embeddings_2[i]]))[0][0]\n",
        "    temp['euclidean_distance'] = manhattan_distances(np.asarray([embeddings_1[i]]), np.asarray([embeddings_2[i]]))[0][0]\n",
        "    distance_and_similarity_scores_6.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A8t8syvWThoJ",
        "colab_type": "code",
        "outputId": "e3e7d56f-4df3-47d5-a8ca-df7809f0fd3a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    print(is_duplicate_questions[i], distance_and_similarity_scores_6[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {'cosine_similarity': 0.9458276, 'manhattan_distance': 1.2538241, 'euclidean_distance': 32.184387501109086}\n",
            "0 {'cosine_similarity': 0.6067528, 'manhattan_distance': 2.9255688, 'euclidean_distance': 112.79561321428446}\n",
            "0 {'cosine_similarity': 0.8873254, 'manhattan_distance': 1.8598092, 'euclidean_distance': 72.58798747658739}\n",
            "0 {'cosine_similarity': 0.5393939, 'manhattan_distance': 3.1896555, 'euclidean_distance': 120.62491884012707}\n",
            "0 {'cosine_similarity': 0.75635266, 'manhattan_distance': 3.1802003, 'euclidean_distance': 131.53287864351518}\n",
            "1 {'cosine_similarity': 0.8199016, 'manhattan_distance': 2.2952108, 'euclidean_distance': 86.52014614462496}\n",
            "0 {'cosine_similarity': 0.3553719, 'manhattan_distance': 3.3347626, 'euclidean_distance': 130.02840969695353}\n",
            "1 {'cosine_similarity': 0.96099097, 'manhattan_distance': 0.75167567, 'euclidean_distance': 19.646674617991266}\n",
            "0 {'cosine_similarity': 1.0, 'manhattan_distance': 0.0, 'euclidean_distance': 1.2594475265359506e-05}\n",
            "0 {'cosine_similarity': 0.7971726, 'manhattan_distance': 2.2010882, 'euclidean_distance': 83.40903483864076}\n",
            "0 {'cosine_similarity': 0.59591144, 'manhattan_distance': 3.379172, 'euclidean_distance': 141.06986477379178}\n",
            "1 {'cosine_similarity': 0.9302225, 'manhattan_distance': 1.104042, 'euclidean_distance': 31.58952859152646}\n",
            "1 {'cosine_similarity': 1.0000002, 'manhattan_distance': 0.0, 'euclidean_distance': 4.345100023783743e-06}\n",
            "1 {'cosine_similarity': 0.960274, 'manhattan_distance': 0.72040766, 'euclidean_distance': 17.49958434590917}\n",
            "0 {'cosine_similarity': 0.970024, 'manhattan_distance': 1.1597912, 'euclidean_distance': 27.432081533150267}\n",
            "1 {'cosine_similarity': 0.8476085, 'manhattan_distance': 2.145061, 'euclidean_distance': 87.41615762085985}\n",
            "1 {'cosine_similarity': 1.0000001, 'manhattan_distance': 0.0, 'euclidean_distance': 0.0}\n",
            "0 {'cosine_similarity': 0.8766564, 'manhattan_distance': 1.6476896, 'euclidean_distance': 58.87347629003125}\n",
            "1 {'cosine_similarity': 0.86601734, 'manhattan_distance': 1.7946079, 'euclidean_distance': 64.51746689830156}\n",
            "0 {'cosine_similarity': 0.8747243, 'manhattan_distance': 1.8397535, 'euclidean_distance': 60.018542632348726}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lIkMtICSThoZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Sentence Encoder V2**"
      ]
    },
    {
      "metadata": {
        "id": "aL2-FeJ-Thoa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://tfhub.dev/google/universal-sentence-encoder/2"
      ]
    },
    {
      "metadata": {
        "id": "mb80PEg1Tho2",
        "colab_type": "code",
        "outputId": "94b104c9-9270-4d78-9267-be8ffe64c37f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install --quiet tensorflow-hub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using pip version 18.1, however version 19.0.3 is available.\n",
            "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gsL8BghuThpQ",
        "colab_type": "code",
        "outputId": "24ed8459-b567-4802-c820-9e38b45fd717",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0310 12:42:12.050889  7768 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JXUgrAajThpr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sp_XRgpWThqd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embed = hub.Module(module_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V-jIYTgxThqq",
        "colab_type": "code",
        "outputId": "5cd7f5e6-c1b5-43fa-f137-8ca1cf5f9f61",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "    sentences_embeddings_1 = session.run(embed(sentences_1[:20]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0310 13:10:26.869572  7768 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0wKn1UHgThq8",
        "colab_type": "code",
        "outputId": "10403a13-5de9-4604-c472-78ea07cbef75",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "    sentences_embeddings_2 = session.run(embed(sentences_2[:20]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0310 13:10:56.016236  7768 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wD8CGKXQThre",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores_8 = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mw2Kb_ohThrs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    temp = {}\n",
        "    temp['cosine_similarity'] = cosine_similarity(np.asarray([sentences_embeddings_1[i]]), np.asarray([sentences_embeddings_2[i]]))[0][0]\n",
        "    temp['manhattan_distance'] = euclidean_distances(np.asarray([sentences_embeddings_1[i]]), np.asarray([sentences_embeddings_2[i]]))[0][0]\n",
        "    temp['euclidean_distance'] = manhattan_distances(np.asarray([sentences_embeddings_1[i]]), np.asarray([sentences_embeddings_2[i]]))[0][0]\n",
        "    distance_and_similarity_scores_8.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "USfurja7Thr7",
        "colab_type": "code",
        "outputId": "b97ab105-8e30-4605-9181-6a26430f3eb5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    print(is_duplicate_questions[i], distance_and_similarity_scores_8[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {'cosine_similarity': 0.9486568, 'manhattan_distance': 0.3204472, 'euclidean_distance': 5.245485807812656}\n",
            "0 {'cosine_similarity': 0.6202224, 'manhattan_distance': 0.8715247, 'euclidean_distance': 14.994461547388255}\n",
            "0 {'cosine_similarity': 0.8335015, 'manhattan_distance': 0.57705903, 'euclidean_distance': 9.815707650494005}\n",
            "0 {'cosine_similarity': 0.2900136, 'manhattan_distance': 1.1916263, 'euclidean_distance': 21.74811126565328}\n",
            "0 {'cosine_similarity': 0.49464017, 'manhattan_distance': 1.0053457, 'euclidean_distance': 17.698465278358526}\n",
            "1 {'cosine_similarity': 0.8778694, 'manhattan_distance': 0.49422783, 'euclidean_distance': 7.790173144967412}\n",
            "0 {'cosine_similarity': 0.16489124, 'manhattan_distance': 1.2923691, 'euclidean_distance': 23.196336368258926}\n",
            "1 {'cosine_similarity': 0.9448141, 'manhattan_distance': 0.33222255, 'euclidean_distance': 5.783593213651329}\n",
            "0 {'cosine_similarity': 1.0, 'manhattan_distance': 0.0, 'euclidean_distance': 0.0}\n",
            "0 {'cosine_similarity': 0.83476865, 'manhattan_distance': 0.574859, 'euclidean_distance': 9.804769292395576}\n",
            "0 {'cosine_similarity': 0.12745847, 'manhattan_distance': 1.3210161, 'euclidean_distance': 23.505938380429143}\n",
            "1 {'cosine_similarity': 0.9092075, 'manhattan_distance': 0.42612785, 'euclidean_distance': 7.400624245405197}\n",
            "1 {'cosine_similarity': 1.0, 'manhattan_distance': 0.0, 'euclidean_distance': 0.0}\n",
            "1 {'cosine_similarity': 0.95513123, 'manhattan_distance': 0.29956242, 'euclidean_distance': 5.218573479010956}\n",
            "0 {'cosine_similarity': 0.97338766, 'manhattan_distance': 0.23070462, 'euclidean_distance': 3.2130904488731176}\n",
            "1 {'cosine_similarity': 0.68606377, 'manhattan_distance': 0.7923839, 'euclidean_distance': 13.379268934691936}\n",
            "1 {'cosine_similarity': 1.0000001, 'manhattan_distance': 0.0, 'euclidean_distance': 0.0}\n",
            "0 {'cosine_similarity': 0.810645, 'manhattan_distance': 0.6153944, 'euclidean_distance': 10.599712683309917}\n",
            "1 {'cosine_similarity': 0.8176981, 'manhattan_distance': 0.60382426, 'euclidean_distance': 10.594791327503117}\n",
            "0 {'cosine_similarity': 0.928566, 'manhattan_distance': 0.37797904, 'euclidean_distance': 6.199734789945069}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0REIjwVNThsP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN and TimeDistributed"
      ]
    },
    {
      "metadata": {
        "id": "ZTLQ5ZJNThsQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/zhihang/an-ensemble-approach-cnn-and-timedistributed"
      ]
    },
    {
      "metadata": {
        "id": "zE6jg7HHThsk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YdMktgOMThsx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXelV3HjThtE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime, time, json\n",
        "from string import punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "awzjplbcThtL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gMqAzlFThtO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TOdeyLYEThtf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import initializers\n",
        "from keras import backend as K\n",
        "from keras.optimizers import SGD\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, Reshape, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
        "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DsJUOT3mThtx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_questions = dataset_p_l_rms_l_1.tolist() + dataset_p_l_rms_l_2.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gNE5S8VTht2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_questions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKbzxzKQTht5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question1_word_sequences = tokenizer.texts_to_sequences(sentences_1.tolist())\n",
        "question2_word_sequences = tokenizer.texts_to_sequences(sentences_2.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjn1esYUThuK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WnTafrvlThuO",
        "colab_type": "code",
        "outputId": "696642d7-77cb-4101-8f7c-71a3fb72fe57",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_question_len = 0\n",
        "for each in range(length):\n",
        "    max_question_len = max(max_question_len, len(question1_word_sequences[each]), len(question2_word_sequences[each]))\n",
        "print(max_question_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i9zDir1ZThuh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_q1 = pad_sequences(question1_word_sequences,\n",
        "                              maxlen = max_question_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0mG5A7_ThvP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_q2 = pad_sequences(question2_word_sequences,\n",
        "                              maxlen = max_question_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bUJJYK2mThvV",
        "colab_type": "code",
        "outputId": "38b345af-b4f3-4e9a-9abf-577aa8c4a865",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with open('E:/Models/pre_trained/glove/wiki/wiki.300d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split(' ')\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = embedding\n",
        "print('Word embeddings:', len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word embeddings: 400001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q1fCQe8jThvz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_dim = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qyRcPN4TThv3",
        "colab_type": "code",
        "outputId": "1284ccd9-f424-43da-fe84-9def942a8f25",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_words = len(word_index)\n",
        "word_embedding_matrix = np.zeros((nb_words + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        word_embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0)) #75,334"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null word embeddings: 20431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "717pXiF4Thv8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "units = 128 # Number of nodes in the Dense layers\n",
        "dropout = 0.25 # Percentage of nodes to drop\n",
        "nb_filter = 32 # Number of filters to use in Convolution1D\n",
        "filter_length = 3 # Length of filter for Convolution1D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DtvBJ-IbThwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=2)\n",
        "bias = bias_initializer='zeros'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kfX5rFLjThwG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eWwGJL0sThwW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_1_input = Input(shape = (max_question_len,), dtype = 'int32', name = 'model_1_input')\n",
        "model_1_embedding = Embedding(nb_words + 1,\n",
        "                     embedding_dim,\n",
        "                     weights = [word_embedding_matrix], \n",
        "                     input_length = max_question_len,\n",
        "                     trainable = False)(model_1_input)\n",
        "model_1_conv_a = Convolution1D(filters = nb_filter, \n",
        "                         kernel_size = filter_length, \n",
        "                         padding = 'same')(model_1_embedding)\n",
        "model_1_batch_a = BatchNormalization()(model_1_conv_a)\n",
        "model_1_act = Activation('relu')(model_1_batch_a)\n",
        "model_1_drop_a = Dropout(dropout)(model_1_act)\n",
        "model_1_conv_b = Convolution1D(filters = nb_filter, \n",
        "                         kernel_size = filter_length, \n",
        "                         padding = 'same')(model_1_drop_a)\n",
        "model_1_batch_b = BatchNormalization()(model_1_conv_b)\n",
        "model_1_act_b = Activation('relu')(model_1_batch_b)\n",
        "model_1_drop_b = Dropout(dropout)(model_1_act_b)\n",
        "model_1_flat = Flatten()(model_1_drop_b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RR3kfYpXThwm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_2_input = Input(shape = (max_question_len,), dtype = 'int32', name = 'model_2_input')\n",
        "model_2_embedding = Embedding(nb_words + 1,\n",
        "                     embedding_dim,\n",
        "                     weights = [word_embedding_matrix], \n",
        "                     input_length = max_question_len,\n",
        "                     trainable = False)(model_2_input)\n",
        "model_2_conv_a = Convolution1D(filters = nb_filter, \n",
        "                         kernel_size = filter_length, \n",
        "                         padding = 'same')(model_2_embedding)\n",
        "model_2_batch_a = BatchNormalization()(model_2_conv_a)\n",
        "model_2_act = Activation('relu')(model_2_batch_a)\n",
        "model_2_drop_a = Dropout(dropout)(model_2_act)\n",
        "model_2_conv_b = Convolution1D(filters = nb_filter, \n",
        "                         kernel_size = filter_length, \n",
        "                         padding = 'same')(model_2_drop_a)\n",
        "model_2_batch_b = BatchNormalization()(model_2_conv_b)\n",
        "model_2_act_b = Activation('relu')(model_2_batch_b)\n",
        "model_2_drop_b = Dropout(dropout)(model_2_act_b)\n",
        "model_2_flat = Flatten()(model_2_drop_b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6XGdYsi-Thwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_3_input = Input(shape = (max_question_len,), dtype = 'int32', name = 'model_3_input')\n",
        "model_3_embedding = Embedding(nb_words + 1,\n",
        "                     embedding_dim,\n",
        "                     weights = [word_embedding_matrix],\n",
        "                     input_length = max_question_len,\n",
        "                     trainable = False)(model_3_input)\n",
        "model_3_time_distributed = TimeDistributed(Dense(embedding_dim))(model_3_embedding)\n",
        "model_3_batch = BatchNormalization()(model_3_time_distributed)\n",
        "model_3_act = Activation('relu')(model_3_batch)\n",
        "model_3_drop = Dropout(dropout)(model_3_act)\n",
        "model_3_lambda = Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim, ))(model_3_drop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZTqDf33Thwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_4_input = Input(shape = (max_question_len,), dtype = 'int32', name = 'model_4_input')\n",
        "model_4_embedding = Embedding(nb_words + 1,\n",
        "                     embedding_dim,\n",
        "                     weights = [word_embedding_matrix],\n",
        "                     input_length = max_question_len,\n",
        "                     trainable = False)(model_4_input)\n",
        "model_4_time_distributed = TimeDistributed(Dense(embedding_dim))(model_4_embedding)\n",
        "model_4_batch = BatchNormalization()(model_4_time_distributed)\n",
        "model_4_act = Activation('relu')(model_4_batch)\n",
        "model_4_drop = Dropout(dropout)(model_4_act)\n",
        "model_4_lambda = Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim, ))(model_4_drop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8qzQZ3v0Thw2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wWTYtVWfThw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "merge_layer = concatenate([model_1_flat, model_2_flat, model_3_lambda, model_4_lambda], name = 'merge_layer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nhi18BHpThw_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = Dense(200, activation = 'relu', name = 'dense1')(merge_layer)\n",
        "t = Dropout(0.3)(t)\n",
        "t = BatchNormalization()(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5gJrwBkThxD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = Dense(200, activation = 'relu', name  ='dense2')(t)\n",
        "t = Dropout(0.3)(t)\n",
        "t = BatchNormalization()(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1UqIRnYQThxJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = Dense(100, activation= 'relu',name = 'dense3')(t)\n",
        "t = Dropout(0.3)(t)\n",
        "t = BatchNormalization()(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JJMX7RW6ThxN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_output = Dense(1, activation = 'sigmoid')(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpEImjZlThxQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdB2f-2YThxU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs = [model_1_input, model_2_input, model_3_input, model_4_input], outputs = final_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmThUDHkThxc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7AvSOq0mThxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_best_weights = 'question_pairs_weights.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8PbDmwHLThxy",
        "colab_type": "code",
        "outputId": "8d8e2d4e-cbcf-4b16-aaa0-b3e34bc6ccc2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "callbacks = [ModelCheckpoint(save_best_weights, monitor='val_loss', save_best_only=True),\n",
        "             EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')]\n",
        "history = model.fit([train_q1, train_q2, train_q1, train_q2],\n",
        "                    questions.is_duplicate,\n",
        "                    batch_size=256,\n",
        "                    epochs=1, #Use 100, I reduce it for Kaggle,\n",
        "                    validation_split=0.15,\n",
        "                    verbose=True,\n",
        "                    shuffle=True,\n",
        "                    callbacks=callbacks)\n",
        "t1 = time.time()\n",
        "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 343695 samples, validate on 60653 samples\n",
            "Epoch 1/1\n",
            "  7680/343695 [..............................] - ETA: 58:10 - loss: 0.7693 - acc: 0.5598"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-65-5d6ff2285de8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                     callbacks=callbacks)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Minutes elapsed: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m60.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\users\\vsriv\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "thlpSipEThyD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "summary_stats = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
        "                              'train_acc': history.history['acc'],\n",
        "                              'valid_acc': history.history['val_acc'],\n",
        "                              'train_loss': history.history['loss'],\n",
        "                              'valid_loss': history.history['val_loss']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RIxZsGW1ThyQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "summary_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULNZPQWZThyU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(summary_stats.train_loss) # blue\n",
        "plt.plot(summary_stats.valid_loss) # green\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNln5hIvThyY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "min_loss, idx = min((loss, idx) for (idx, loss) in enumerate(history.history['val_loss']))\n",
        "print('Minimum loss at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(min_loss))\n",
        "min_loss = round(min_loss, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kYsJiuRnThyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(save_best_weights)\n",
        "predictions = model.predict([test_q1, test_q2, test_q1, test_q2], verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "elQTFbMuHhgN"
      },
      "cell_type": "markdown",
      "source": [
        "**Siamese Neural Networks(Using LSTM and GRU)**"
      ]
    },
    {
      "metadata": {
        "id": "a1ln-4sTThyx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://medium.com/mlreview/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dE_9Xb7uHqgw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "import keras.backend as backend\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda, GRU, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DWJ7T5-xThy_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocabulary = dict()\n",
        "inverse_vocabulary = ['<unk>']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lDqBuGauThzJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q2n_left = []\n",
        "for sentence in sentences_1.tolist():\n",
        "    temp_sentence = []\n",
        "    for word in sentence.split():\n",
        "        if word not in vocabulary:\n",
        "            vocabulary[word] = len(inverse_vocabulary)\n",
        "            temp_sentence.append(len(inverse_vocabulary))\n",
        "            inverse_vocabulary.append(word)\n",
        "        else:\n",
        "            temp_sentence.append(vocabulary[word])\n",
        "    q2n_left.append(temp_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TUOuLqh0ThzV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q2n_right = []\n",
        "for sentence in sentences_2.tolist():\n",
        "    temp_sentence = []\n",
        "    for word in sentence.split():\n",
        "        if word not in vocabulary:\n",
        "            vocabulary[word] = len(inverse_vocabulary)\n",
        "            temp_sentence.append(len(inverse_vocabulary))\n",
        "            inverse_vocabulary.append(word)\n",
        "        else:\n",
        "            temp_sentence.append(vocabulary[word])\n",
        "    q2n_right.append(temp_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d12cT2W6Thzh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "embeddings = np.zeros((len(vocabulary) + 1, embedding_dim))\n",
        "embeddings[0] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgJE5IG_Thz1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for word, index in vocabulary.items():\n",
        "    if word in google_model.vocab:\n",
        "        embeddings[index] = google_model.word_vec(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yylXEJPThz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del google_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpjEmyWSTh0H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6cdNIb5rTh0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_left = q2n_left"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c6xYqZ0CTh0O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_right = q2n_right"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nx1ohcwUTh0Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_seq_length = 0\n",
        "for each in range(length):\n",
        "    max_seq_length = max(max_seq_length, len(q2n_left[each]), len(q2n_right[each]))\n",
        "print(max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a0A4__Z7Th0m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_left = pad_sequences(q2n_left, maxlen=max_seq_length)\n",
        "dataset_right = pad_sequences(q2n_right, maxlen=max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0tRbrmVTh0v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_left.shape == dataset_right.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mv21EhXoTh1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_hidden1 = 512\n",
        "n_hidden2 = 384\n",
        "n_hidden3 = 256\n",
        "n_hidden4 = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WljRtYIvJcTn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "left_input = Input(shape=(max_seq_length, ), dtype='int32')\n",
        "right_input = Input(shape=(max_seq_length, ), dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ksWe8MukKbxW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], \n",
        "                            input_length=max_seq_length, trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "U0jTBGv4Kck8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded_left = embedding_layer(left_input)\n",
        "encoded_right = embedding_layer(right_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5e9B1ChNKgA3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shared_lstm1 = LSTM(n_hidden1, return_sequences=True)\n",
        "shared_dropout1 = Dropout(0.3)\n",
        "shared_gru1 = GRU(n_hidden2, return_sequences=True)\n",
        "shared_dropout2 = Dropout(0.4)\n",
        "shared_gru2 = GRU(n_hidden3, return_sequences=True)\n",
        "shared_dropout3 = Dropout(0.3)\n",
        "shared_lstm2 = LSTM(n_hidden4, return_sequences=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oiSpiz9uLGu3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "left_lstm1 = shared_lstm1(encoded_left)\n",
        "left_dropout1 = shared_dropout1(left_lstm1)\n",
        "left_gru1 = shared_gru1(left_dropout1)\n",
        "left_dropout2 = shared_dropout2(left_gru1)\n",
        "left_gru2 = shared_gru2(left_dropout2)\n",
        "left_dropout3 = shared_dropout3(left_gru2)\n",
        "left_lstm2 = shared_lstm2(left_dropout3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bcQJfYn6Ma5S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "right_lstm1 = shared_lstm1(encoded_right)\n",
        "right_dropout1 = shared_dropout1(right_lstm1)\n",
        "right_gru1 = shared_gru1(right_dropout1)\n",
        "right_dropout2 = shared_dropout2(right_gru1)\n",
        "right_gru2 = shared_gru2(right_dropout2)\n",
        "right_dropout3 = shared_dropout3(right_gru2)\n",
        "right_lstm2 = shared_lstm2(right_dropout3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ug1R5gTGM4oR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "manhattan_distance_for_lstm = Lambda(function=lambda x: backend.exp(-backend.sum(backend.abs(x[0]-x[1]), axis=1, keepdims=True)),\n",
        "                                     output_shape=lambda x: (x[0][0], 1))([left_lstm2, right_lstm2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3dWiDq3dUK7m"
      },
      "cell_type": "markdown",
      "source": [
        "**Training and Validation**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6fkjFhAkT8Ov",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gNlq-mXyUjO9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stratkfold = StratifiedKFold(n_splits=2, random_state=None, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "n5TGTK2CUrN8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for train_index, test_index in stratkfold.split(dataset_left, is_duplicate_questions):\n",
        "    siamese_network = Model([left_input, right_input], manhattan_distance_for_lstm)\n",
        "    siamese_network.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=['accuracy'])\n",
        "    siamese_network.fit([dataset_left[train_index], dataset_right[train_index]], is_duplicate_questions[train_index], batch_size=128, \n",
        "                        epochs=128, validation_data=([dataset_left[test_index], dataset_right[test_index]], is_duplicate_questions[test_index]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UGyxnRuCHe6T"
      },
      "cell_type": "markdown",
      "source": [
        "# Spell Corrector"
      ]
    },
    {
      "metadata": {
        "id": "4fnA8VxlTh3Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8U9QUzGUHe6U",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "**Word Corrector**"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v_XrA4LyTh3u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bg_FeMqnTh31",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def words(text): \n",
        "    return re.findall(r'\\w+', text.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6J6T2d4Th4R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "WORDS = Counter(words(open('data/big.txt').read()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HeI0KAFTh4l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def probability(word, n=sum(WORDS.values())): \n",
        "    return WORDS[word] / n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NJr41cJkTh4y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def correction(word): \n",
        "    return max(candidates(word), key=probability)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dt26j27lTh4-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def candidates(word): \n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LE_qAgyiTh5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def known(words):\n",
        "    return set(w for w in words if w in WORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16NeTmkOTh5L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def edits1(word):\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bLqZSRjkTh5a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def edits2(word):\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Em0idSRBHe6V"
      },
      "cell_type": "markdown",
      "source": [
        "**Sentence Corrector**"
      ]
    },
    {
      "metadata": {
        "id": "njfGzwZZTh5u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QH_YL3AeTh5y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"data/words_dictionary.json\") as words_dictionary_file:\n",
        "    word_dict = json.load(words_dictionary_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IAKle4mfTh6E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def correct_sentences(sentence):\n",
        "    sentence = sentence.lower().split()\n",
        "    combination_sentences = []\n",
        "    combination_probabilities = []\n",
        "    meta_data = {}\n",
        "    for each in sentence:\n",
        "        if not word_dict.get(each, None):\n",
        "            possible_words = candidates(each)\n",
        "            probabilities = []\n",
        "            for each_word in possible_words:\n",
        "                probabilities.append(probability(each_word))\n",
        "            meta_data[each] = [list(possible_words), list(probabilities)]\n",
        "    for i in range(len(sentence)):\n",
        "        if meta_data.get(sentence[i], None):\n",
        "            for each in meta_data[sentence[i]][0]:\n",
        "                combination_sentences.append(\" \".join(sentence[:i]) + \" \" + each + \" \".join(sentence[i+1:]))\n",
        "    return combination_sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W4ODlAk9Th6I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct_sentences(\"Every thing comes with a pricee\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5JJvGGQUWQi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Wordnet"
      ]
    },
    {
      "metadata": {
        "id": "_6e3SF06RbWv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **`Sementic Similarity using Wordnet`**"
      ]
    },
    {
      "metadata": {
        "id": "0A2z0WX4l10m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "https://www.kaggle.com/antriksh5235/semantic-similarity-using-wordnet/data"
      ]
    },
    {
      "metadata": {
        "id": "ubIsmYMkRnFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ojcmqNtZRO7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing basic stuff**\n"
      ]
    },
    {
      "metadata": {
        "id": "xgvZpuG1l68h",
        "colab_type": "code",
        "outputId": "baea7ec6-439c-4692-b8a4-6e6f30a45c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import math\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "_hyUdr-DR7IX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tokenization, POS Tagging and Stemming**"
      ]
    },
    {
      "metadata": {
        "id": "s0I-AKi0mFa2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def tokenize(q1, q2):\n",
        "    \"\"\"\n",
        "        q1 and q2 are sentences/questions. Function returns a list of tokens for both.\n",
        "    \"\"\"\n",
        "    return word_tokenize(q1), word_tokenize(q2)\n",
        "\n",
        "\n",
        "def posTag(q1, q2):\n",
        "    \"\"\"\n",
        "        q1 and q2 are lists. Function returns a list of POS tagged tokens for both.\n",
        "    \"\"\"\n",
        "    return nltk.pos_tag(q1), nltk.pos_tag(q2)\n",
        "\n",
        "\n",
        "def stemmer(tag_q1, tag_q2):\n",
        "    \"\"\"\n",
        "        tag_q = tagged lists. Function returns a stemmed list.\n",
        "    \"\"\"\n",
        "\n",
        "    stem_q1 = []\n",
        "    stem_q2 = []\n",
        "\n",
        "    for token in tag_q1:\n",
        "        stem_q1.append(stem(token))\n",
        "\n",
        "    for token in tag_q2:\n",
        "        stem_q2.append(stem(token))\n",
        "\n",
        "    return stem_q1, stem_q2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mXRj0NX6SNxQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Lesk Algorithm for word sense disambiguation**"
      ]
    },
    {
      "metadata": {
        "id": "6z5s6PotmG-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Lesk(object):\n",
        "\n",
        "    def __init__(self, sentence):\n",
        "        self.sentence = sentence\n",
        "        self.meanings = {}\n",
        "        for word in sentence:\n",
        "            self.meanings[word] = ''\n",
        "\n",
        "    def getSenses(self, word):\n",
        "        # print word\n",
        "        return wn.synsets(word.lower())\n",
        "\n",
        "    def getGloss(self, senses):\n",
        "\n",
        "        gloss = {}\n",
        "\n",
        "        for sense in senses:\n",
        "            gloss[sense.name()] = []\n",
        "\n",
        "        for sense in senses:\n",
        "            gloss[sense.name()] += word_tokenize(sense.definition())\n",
        "\n",
        "        return gloss\n",
        "\n",
        "    def getAll(self, word):\n",
        "        senses = self.getSenses(word)\n",
        "\n",
        "        if senses == []:\n",
        "            return {word.lower(): senses}\n",
        "\n",
        "        return self.getGloss(senses)\n",
        "\n",
        "    def Score(self, set1, set2):\n",
        "        # Base\n",
        "        overlap = 0\n",
        "\n",
        "        # Step\n",
        "        for word in set1:\n",
        "            if word in set2:\n",
        "                overlap += 1\n",
        "\n",
        "        return overlap\n",
        "\n",
        "    def overlapScore(self, word1, word2):\n",
        "\n",
        "        gloss_set1 = self.getAll(word1)\n",
        "        if self.meanings[word2] == '':\n",
        "            gloss_set2 = self.getAll(word2)\n",
        "        else:\n",
        "            # print 'here'\n",
        "            gloss_set2 = self.getGloss([wn.synset(self.meanings[word2])])\n",
        "\n",
        "        # print gloss_set2\n",
        "\n",
        "        score = {}\n",
        "        for i in gloss_set1.keys():\n",
        "            score[i] = 0\n",
        "            for j in gloss_set2.keys():\n",
        "                score[i] += self.Score(gloss_set1[i], gloss_set2[j])\n",
        "\n",
        "        bestSense = None\n",
        "        max_score = 0\n",
        "        for i in gloss_set1.keys():\n",
        "            if score[i] > max_score:\n",
        "                max_score = score[i]\n",
        "                bestSense = i\n",
        "\n",
        "        return bestSense, max_score\n",
        "\n",
        "    def lesk(self, word, sentence):\n",
        "        maxOverlap = 0\n",
        "        context = sentence\n",
        "        word_sense = []\n",
        "        meaning = {}\n",
        "\n",
        "        senses = self.getSenses(word)\n",
        "\n",
        "        for sense in senses:\n",
        "            meaning[sense.name()] = 0\n",
        "\n",
        "        for word_context in context:\n",
        "            if not word == word_context:\n",
        "                score = self.overlapScore(word, word_context)\n",
        "                if score[0] == None:\n",
        "                    continue\n",
        "                meaning[score[0]] += score[1]\n",
        "\n",
        "        if senses == []:\n",
        "            return word, None, None\n",
        "\n",
        "        self.meanings[word] = max(meaning.keys(), key=lambda x: meaning[x])\n",
        "\n",
        "        return word, self.meanings[word], wn.synset(self.meanings[word]).definition()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iO_xsbmWSUf6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Similarity based on distance of the words in the hyponym taxonymy graph**"
      ]
    },
    {
      "metadata": {
        "id": "0Cw0wlHsmNDq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.metrics import edit_distance\n",
        "\n",
        "def path(set1, set2):\n",
        "    return wn.path_similarity(set1, set2)\n",
        "\n",
        "\n",
        "def wup(set1, set2):\n",
        "    return wn.wup_similarity(set1, set2)\n",
        "\n",
        "\n",
        "def edit(word1, word2):\n",
        "    if float(edit_distance(word1, word2)) == 0.0:\n",
        "        return 0.0\n",
        "    return 1.0 / float(edit_distance(word1, word2))\n",
        "\n",
        "def computePath(q1, q2):\n",
        "\n",
        "    R = np.zeros((len(q1), len(q2)))\n",
        "\n",
        "    for i in range(len(q1)):\n",
        "        for j in range(len(q2)):\n",
        "            if q1[i][1] == None or q2[j][1] == None:\n",
        "                sim = edit(q1[i][0], q2[j][0])\n",
        "            else:\n",
        "                sim = path(wn.synset(q1[i][1]), wn.synset(q2[j][1]))\n",
        "\n",
        "            if sim == None:\n",
        "                sim = edit(q1[i][0], q2[j][0])\n",
        "\n",
        "            R[i, j] = sim\n",
        "\n",
        "    # print R\n",
        "\n",
        "    return R\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7maF9mNiShj-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Wup Similarity**"
      ]
    },
    {
      "metadata": {
        "id": "gzWj6wAImRan",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def computeWup(q1, q2):\n",
        "\n",
        "    R = np.zeros((len(q1), len(q2)))\n",
        "\n",
        "    for i in range(len(q1)):\n",
        "        for j in range(len(q2)):\n",
        "            if q1[i][1] == None or q2[j][1] == None:\n",
        "                sim = edit(q1[i][0], q2[j][0])\n",
        "            else:\n",
        "                sim = wup(wn.synset(q1[i][1]), wn.synset(q2[j][1]))\n",
        "\n",
        "            if sim == None:\n",
        "                sim = edit(q1[i][0], q2[j][0])\n",
        "\n",
        "            R[i, j] = sim\n",
        "\n",
        "    # print R\n",
        "\n",
        "    return R"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZgvddNKJSotd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Overall Similarity**"
      ]
    },
    {
      "metadata": {
        "id": "x6X7CsUGmaK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def overallSim(q1, q2, R):\n",
        "\n",
        "    sum_X = 0.0\n",
        "    sum_Y = 0.0\n",
        "\n",
        "    for i in range(len(q1)):\n",
        "        max_i = 0.0\n",
        "        for j in range(len(q2)):\n",
        "            if R[i, j] > max_i:\n",
        "                max_i = R[i, j]\n",
        "        sum_X += max_i\n",
        "\n",
        "    for i in range(len(q1)):\n",
        "        max_j = 0.0\n",
        "        for j in range(len(q2)):\n",
        "            if R[i, j] > max_j:\n",
        "                max_j = R[i, j]\n",
        "        sum_Y += max_j\n",
        "        \n",
        "    if (float(len(q1)) + float(len(q2))) == 0.0:\n",
        "        return 0.0\n",
        "        \n",
        "    overall = (sum_X + sum_Y) / (2 * (float(len(q1)) + float(len(q2))))\n",
        "\n",
        "    return overall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LhuOMv33StGl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Semantic similarity between two sentences**"
      ]
    },
    {
      "metadata": {
        "id": "X90ALUy3ml1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def semanticSimilarity(q1, q2):\n",
        "\n",
        "    tokens_q1, tokens_q2 = tokenize(q1, q2)\n",
        "    # stem_q1, stem_q2 = stemmer(tokens_q1, tokens_q2)\n",
        "    tag_q1, tag_q2 = posTag(tokens_q1, tokens_q2)\n",
        "\n",
        "    sentence = []\n",
        "    for i, word in enumerate(tag_q1):\n",
        "        if 'NN' in word[1] or 'JJ' in word[1] or 'VB' in word[1]:\n",
        "            sentence.append(word[0])\n",
        "\n",
        "    sense1 = Lesk(sentence)\n",
        "    sentence1Means = []\n",
        "    for word in sentence:\n",
        "        sentence1Means.append(sense1.lesk(word, sentence))\n",
        "\n",
        "    sentence = []\n",
        "    for i, word in enumerate(tag_q2):\n",
        "        if 'NN' in word[1] or 'JJ' in word[1] or 'VB' in word[1]:\n",
        "            sentence.append(word[0])\n",
        "\n",
        "    sense2 = Lesk(sentence)\n",
        "    sentence2Means = []\n",
        "    for word in sentence:\n",
        "        sentence2Means.append(sense2.lesk(word, sentence))\n",
        "    # for i, word in enumerate(sentence1Means):\n",
        "    #     print sentence1Means[i][0], sentence2Means[i][0]\n",
        "\n",
        "    R1 = computePath(sentence1Means, sentence2Means)\n",
        "    R2 = computeWup(sentence1Means, sentence2Means)\n",
        "\n",
        "    R = (R1 + R2) / 2\n",
        "\n",
        "\n",
        "    # print R\n",
        "\n",
        "    return overallSim(sentence1Means, sentence2Means, R)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nAdTPpUGSyu9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preprocessing (if needed)**"
      ]
    },
    {
      "metadata": {
        "id": "SzTuoDIfoQmk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "STOP_WORDS = nltk.corpus.stopwords.words()\n",
        "def clean_sentence(val):\n",
        "    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n",
        "    regex = re.compile('([^\\s\\w]|_)+')\n",
        "    sentence = regex.sub('', val).lower()\n",
        "    sentence = sentence.split(\" \")\n",
        "\n",
        "    for word in list(sentence):\n",
        "        if word in STOP_WORDS:\n",
        "            sentence.remove(word)\n",
        "\n",
        "    sentence = \" \".join(sentence)\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qojPY03XTFhm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Testing with custom sentences**"
      ]
    },
    {
      "metadata": {
        "id": "x3WcqzGcmrpW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x=\"for every action there is an equal and opposite reaction\"\n",
        "y=\"for every action there is no reaction\"\n",
        "sim = semanticSimilarity(x, y)*2\n",
        "print(sim)\n",
        "\n",
        "x=\"for every action there is an equal and opposite reaction\"\n",
        "y=\"for every action there is an equal and opposite reaction\"\n",
        "sim = semanticSimilarity(x, y)*2\n",
        "print(sim)\n",
        "\n",
        "x=\"for every action there is an equal and opposite reaction\"\n",
        "y=\"for every action there is a unequal and similar reaction\"\n",
        "sim = semanticSimilarity(x, y)*2\n",
        "print(sim)\n",
        "\n",
        "x=\"I love peace\"\n",
        "y=\"I love war\"\n",
        "sim = semanticSimilarity(x, y)*2\n",
        "print(sim)\n",
        "\n",
        "x=\"This is a cat\"\n",
        "y=\"This is a dog\"\n",
        "sim = semanticSimilarity(x, y)*2\n",
        "print(sim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fZxnlZv1YF3B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Keyword Matching with Wordnet"
      ]
    },
    {
      "metadata": {
        "id": "0UWcEvfXYMWj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**`Importing packages`**"
      ]
    },
    {
      "metadata": {
        "id": "gXL-uitBw5M5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mGPAz7YbYUD_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Setting up answer keys**"
      ]
    },
    {
      "metadata": {
        "id": "BlNLf-HSv28G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "answer_keys = []\n",
        "\n",
        "\n",
        "answer_keys.append({\n",
        "    'question_no' : 1,\n",
        "    'answer' : [\"the principle that the speed and capability of computers can be expected to double every two years, as a result of increases in the number of transistors a microchip can contain\"],\n",
        "    'exact' : True,\n",
        "    'type' : \"keyword\",\n",
        "    'keywords': {\n",
        "        'total_score' : 1,\n",
        "        'words' : ['speed','double','two'],\n",
        "        'words_score'  : [0.5,0.75,0.75]\n",
        "    }\n",
        "})\n",
        "\n",
        "\n",
        "answer_keys.append({\n",
        "    'question_no' : 2,\n",
        "    'answer' : [\"the natural agent that stimulates sight and makes things visible\"],\n",
        "    'exact' : False,\n",
        "    'type' : \"keyword\",\n",
        "    'keywords': {\n",
        "        'total_score' : 1,\n",
        "        'words' : [\"natural\", \"visible\"],\n",
        "        'words_score'  : [0.5, 0.5]\n",
        "    }\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hafg9Ar_wK-T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Setting Up Student Answer**"
      ]
    },
    {
      "metadata": {
        "id": "NSt1hzTvwOEq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "students_answers = []\n",
        "\n",
        "students_answers.append({\n",
        "    \"student_id\": 1,\n",
        "    \"answers\"   : [{\n",
        "        \"question_no\" : 1,\n",
        "        \"answer\"      : [\"the principle that the speed and capability of computers can be expected to double every two years, as a result of increases in the number of transistors a microchip can contain\"]\n",
        "    },{\n",
        "        \"question_no\" : 2,\n",
        "        \"answer\"       :[\"the natural agent that stimulates sight and makes things visible\"]\n",
        "    }]\n",
        "})\n",
        "        \n",
        "  \n",
        "students_answers.append({\n",
        "    \"student_id\": 2,\n",
        "    \"answers\"   : [{\n",
        "        \"question_no\" : 1,\n",
        "        \"answer\"      : [\"the principle that the pace and capability of computers can be expected to double every two years\"]\n",
        "    },{\n",
        "        \"question_no\" : 2,\n",
        "        \"answer\"      :[\"the natural agent that stimulates sight\"]\n",
        "    }]\n",
        "})\n",
        "\n",
        "answers_length = len(answer_keys)\n",
        "print(students_answers[current_answer][\"answers\"][0]['answer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "htbuy4V00qgK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Different Methods of Evaluation**"
      ]
    },
    {
      "metadata": {
        "id": "VuYNXD-8-bEl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "meta_scores = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QRBA9LU0YsWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Exact match**"
      ]
    },
    {
      "metadata": {
        "id": "0jP0JDngwfBv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def keyword_similarity(answer_key, answer):\n",
        "    if answer_key[\"question_no\"] != answer[\"question_no\"]:\n",
        "         assert(\"Question No does not match\")\n",
        "    score = 0\n",
        "    for keyword_index in range(len(answer_key['keywords']['words'])):\n",
        "        if answer_key['keywords']['words'][keyword_index] in answer['answer'][0]:\n",
        "            score += answer_key['keywords']['words_score'][keyword_index] * answer_key['keywords']['total_score']\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8lR00i3BYvkh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Semantically similar Keyword**"
      ]
    },
    {
      "metadata": {
        "id": "piH8UP69zRs4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def keyword_similarity_concept(answer_key, answer):\n",
        "    if answer_key[\"question_no\"] != answer[\"question_no\"]:\n",
        "         assert(\"Question No does not match\")\n",
        "    score = 0\n",
        "    for keyword_index in range(len(answer_key['keywords']['words'])):\n",
        "        if synonymous_in_some_way(  answer_key['keywords']['words'][keyword_index], answer['answer'][0]):\n",
        "            score += answer_key['keywords']['words_score'][keyword_index] * answer_key['keywords']['total_score']\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sBnt6EwJY27k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Checking across possible synonyms**"
      ]
    },
    {
      "metadata": {
        "id": "NnN66JyMzxVy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def synonymous_in_some_way(keywords,answer):\n",
        " \n",
        "  print (\"answer\")\n",
        "  print(answer)\n",
        "  keyword_syn= wn.synsets(keywords)\n",
        "  answer_arr= answer.split(\" \")\n",
        "  \n",
        "  for answer_word in answer_arr:\n",
        "    current_syn= wn.synsets(answer_word)\n",
        "    \n",
        "    for similar_keywords in keyword_syn:\n",
        "      for similar_answers in current_syn:\n",
        "        if not similar_keywords.wup_similarity(similar_answers)==None and similar_keywords.wup_similarity(similar_answers)>0.9:\n",
        "          return True\n",
        "        \n",
        "  return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PlwwDZXBY8Yf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Perform check for analysis**"
      ]
    },
    {
      "metadata": {
        "id": "O9aNad2nwmhX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for index in range(answers_length):\n",
        "    temp_meta_score = []\n",
        "    print (\"index no.\")\n",
        "    print (index)\n",
        "    \n",
        "    for current_answer in range( len(students_answers)):\n",
        "      if answer_keys[index]['exact'] and answer_keys[index]['type'] == \"law\":\n",
        "          count_vectorizer = CountVectorizer()\n",
        "          count_vectorizer.fit(answer_keys[index]['answer'] + students_answers[current_answer][\"answers\"][index]['answer'])\n",
        "          x = count_vectorizer.transform(answer_keys[index]['answer'])\n",
        "          y = count_vectorizer.transform(students_answers[current_answer][\"answers\"][0][\"answer\"])\n",
        "          meta_scores.append({\n",
        "          \"Euclidean Distance\" : euclidean_distances(x, y).ravel()[0],\n",
        "          \"Manhattan Distance\" : manhattan_distances(x, y).ravel()[0]\n",
        "          })\n",
        "\n",
        "      elif answer_keys[index]['exact'] and answer_keys[index]['type'] == \"keyword\":\n",
        "        \n",
        "          meta_scores.append({\n",
        "          \"Keyword Similariy\": keyword_similarity_exact(answer_keys[index], students_answers[current_answer][\"answers\"][index])})\n",
        "          print (\"mytime\")\n",
        "\n",
        "      elif not answer_keys[index]['exact'] and answer_keys[index]['type'] == \"keyword\":\n",
        "          meta_scores.append({\n",
        "          \"Keyword Similariy\": keyword_similarity_concept(answer_keys[index], students_answers[current_answer][\"answers\"][index])})\n",
        "          print(\"Exectued\")\n",
        "\n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xuqPmeAJZB1q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Printing Results**"
      ]
    },
    {
      "metadata": {
        "id": "LM9Lm9ruwp5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(meta_scores)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}