{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iku_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vsrivatsan2096/iku/blob/master/Iku_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "U3hUGck-ksJp"
      },
      "cell_type": "markdown",
      "source": [
        "# Pre-Trained embeddings# Semantics Similarity"
      ]
    },
    {
      "metadata": {
        "id": "gkwbULzr7SxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "507f6fa8-3683-43d3-937a-48ab691bb335"
      },
      "cell_type": "code",
      "source": [
        "!wget \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-14 16:46:29--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.169.205\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.169.205|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  36.8MB/s    in 44s     \n",
            "\n",
            "2019-03-14 16:47:14 (35.9 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9w0yozQi7StP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "fdc41bfd-753e-4433-e517-db306e4a1b4a"
      },
      "cell_type": "code",
      "source": [
        "!wget \"http://nlp.stanford.edu/data/glove.840B.300d.zip\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-14 16:15:50--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2019-03-14 16:15:50--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  15.7MB/s    in 4m 4s   \n",
            "\n",
            "2019-03-14 16:19:55 (8.51 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z06Y-Te17SqS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_oJcaxd07SnH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wiki_zip = zipfile.ZipFile('glove.840B.300d.zip')\n",
        "wiki_zip.extractall()\n",
        "os.remove(\"glove.840B.300d.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPGycXAI7Shk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/infersent/infersent1.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWhDPQlJ7bNn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "infersent_embeddings = 'infersent1.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4mNLSIlm7bJX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "google_embeddings = 'GoogleNews-vectors-negative300.bin.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T3qMkivX7bEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "common_crawl_embeddings = 'glove.840B.300d.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LPXZlsook9cd"
      },
      "cell_type": "markdown",
      "source": [
        "# Installing the Libraries"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AqGfhdAakih2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q numpy\n",
        "!pip install -U -q keras\n",
        "!pip install -U -q scikit-learn\n",
        "!pip install -U -q matplotlib\n",
        "!pip install -U -q nltk\n",
        "!pip install -U -q PyDrive \n",
        "!pip install -U -q pandas\n",
        "!pip install -U -q https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-win_amd64.whl\n",
        "!pip install -U -q torchvision\n",
        "!pip install --quiet tensorflow-hub\n",
        "!pip install --quiet seaborn\n",
        "!pip install --quiet \"tensorflow>=1.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "016VNjCml2NW"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Drive"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3TEWzFSplqVP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07fa7230-c7c4-44a0-f61d-04aeddb44e08"
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import json"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 15.5MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 5.5MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 7.7MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 4.5MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 5.5MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 6.4MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 6.9MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 7.7MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 8.5MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 7.2MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 7.4MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 9.3MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 8.9MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 15.4MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 14.3MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 13.9MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 14.8MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 15.0MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 14.8MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 16.4MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 16.6MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 16.8MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 18.3MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 18.2MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 20.5MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 20.2MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 20.8MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 21.2MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 21.2MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 41.4MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 43.1MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 42.5MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 42.8MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 39.3MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 40.1MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 44.7MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 27.2MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 26.1MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 26.3MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 26.3MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 26.4MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 26.6MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 26.4MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 26.6MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 26.7MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 26.3MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 41.1MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 43.8MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 44.7MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 42.0MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 41.9MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 41.6MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 42.3MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 46.4MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 46.2MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 36.0MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 36.5MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 36.1MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 32.9MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 34.3MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 34.4MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 34.1MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 34.1MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 33.9MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 27.6MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 33.9MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 34.0MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 34.1MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 38.0MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 38.4MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 38.7MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 38.6MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 37.5MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 37.5MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 42.8MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 42.0MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 42.7MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 39.6MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 38.7MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 37.7MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 36.3MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 36.0MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 36.5MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 32.2MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 36.1MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 37.0MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 36.0MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 38.6MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 39.1MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 40.2MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 41.3MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 41.3MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 42.2MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 40.8MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 40.7MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 40.4MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 14.4MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GSqhf7dHl_SS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MqJZtt-HmF6v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_ids = [\"1bqdQccb6176JhXU7CZbWnv3vTAi7BH_-\"]\n",
        "file_names = ['questions.csv']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nLtygnFNmLx_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for each_id, each_name in zip(file_ids, file_names):\n",
        "    download = drive.CreateFile({'id':each_id})\n",
        "    download.GetContentFile(each_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nb0JqtLo8Qz9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "metadata": {
        "id": "Bc5y_OsN8QMx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-T82dnp8Vtd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Cloning Github"
      ]
    },
    {
      "metadata": {
        "id": "YuAlla988Y48",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vsrivatsan2096/iku.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HNPMenzA0Yyj"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "J3Z7qyzq0g6Q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bM1togrSTgrm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "questions = pd.read_csv(\"questions.csv\")\n",
        "questions.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N3hpXv-GTgup",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "questions1 = questions.iloc[:, 3].values\n",
        "questions2 = questions.iloc[:, 4].values\n",
        "is_duplicate_questions = questions.iloc[:, 5].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nVTLX122TgyM",
        "colab_type": "code",
        "outputId": "bc9113ed-37cf-477b-c2dc-e4c315fa0e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "questions.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sjk1awi9vns5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mNVsrA9WHe5b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "length = is_duplicate_questions.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xCi7z0cr8tIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Scores"
      ]
    },
    {
      "metadata": {
        "id": "oF9or-MN8xDA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import manhattan_distances\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.metrics import jaccard_similarity_score\n",
        "from sklearn.neighbors import DistanceMetric"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7OiGlv2-Ikq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cosine_similarity(self, sentence1, sentence2):\n",
        "    return cosine_similarity(sentence1.reshape(1, -1), sentence2.reshape(1, -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OI-2pT5A-IcO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def manhattan_distances(self, sentence1, sentence2):\n",
        "    return manhattan_distances(sentence1.reshape(1, -1), sentence2.reshape(1, -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U5Qz5hkM-IVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def euclidean_distances(self, sentence1, sentence2):\n",
        "    return euclidean_distances(sentence1.reshape(1, -1), sentence2.reshape(1, -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4iQZeg5V-IPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(self, sentence1, sentence2):\n",
        "    jac_score = 0\n",
        "    try:\n",
        "        jac_score = jaccard_similarity_score(sentence1.reshape(1, -1), sentence2.reshape(1, -1))\n",
        "    finally:\n",
        "        return jac_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_58YfrGX-N-8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def minkowski_distances(self, sentence1, sentence2):\n",
        "    minkowski_distance = DistanceMetric.get_metric('minkowski')\n",
        "    return minkowski_distance.pairwise(sentence1.reshape(1, -1), sentence2.reshape(1, -1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "slLOTw3x-Sb8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_scores(self, sentences1, sentences2, length):\n",
        "    scores = []\n",
        "    for each in range(length):\n",
        "        each_score = []\n",
        "        each_score.append(self.cosine_similarity(sentences1[each], sentences2[each])[0][0])\n",
        "        each_score.append(self.manhattan_distances(sentences1[each], sentences2[each])[0][0])\n",
        "        each_score.append(self.euclidean_distances(ssentences1[each], sentences2[each])[0][0])\n",
        "        #each_score.append(self.jaccard_similarity(self.sentences1[each], self.sentences2[each]))\n",
        "        each_score.append(self.minkowski_distances(sentences1[each], sentences2[each])[0][0])\n",
        "        scores[each] = np.asarray(each_score)\n",
        "    return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "k7q4ZLpcKj0v"
      },
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3TEybJIOKkgT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.utils import simple_preprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uRnXzsycKsMg",
        "outputId": "bc09c286-c1e9-4f0d-b2b7-afff39ca6419",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KTPkxZdiK0BD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lemma = WordNetLemmatizer()\n",
        "stopword = stopwords.words(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rd75AVttK7hD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences_1 = []\n",
        "for i in questions1:\n",
        "    tempx = re.sub(r\"[^A-Za-z]\", \" \", str(i))\n",
        "    tempx = tempx.lower().split()\n",
        "    tempx = [word for word in tempx if word not in stopword]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"a\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"r\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"n\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"v\") for word in tempx]\n",
        "    sentences_1.append(\" \".join(tempx))\n",
        "sentences_1 = np.asarray(sentences_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HdAWSHcJHe5q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences_2 = []\n",
        "for i in questions2:\n",
        "    tempx = re.sub(r\"[^A-Za-z]\", \" \", str(i))\n",
        "    tempx = tempx.lower().split()\n",
        "    tempx = [word for word in tempx if word not in stopword]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"a\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"r\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"n\") for word in tempx]\n",
        "    tempx = [lemma.lemmatize(word, pos=\"v\") for word in tempx]\n",
        "    sentences_2.append(\" \".join(tempx))\n",
        "sentences_2 = np.asarray(sentences_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "w-xcGFtPGdfJ"
      },
      "cell_type": "markdown",
      "source": [
        "# LSA Method"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jYXzCvrQGgm3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LHMV-1Bhai1e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2DObvs6mal97",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "svd_model = TruncatedSVD(n_components=300,\n",
        "                         algorithm='randomized',\n",
        "                         n_iter=10, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "__L-nT-lapFP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsa_model1 = Pipeline([('tfidf', vectorizer), \n",
        "                            ('svd', svd_model)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cCFrhTD-He55",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsa_model2 = Pipeline([('tfidf', vectorizer), \n",
        "                            ('svd', svd_model)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d0Qm7cU-asMM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lsa_1 = lsa_model1.fit_transform(sentences_1)\n",
        "lsa_2 = lsa_model2.fit_transform(sentences_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ShsDeBj0He59",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores_3 = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t-RqCVPvHe5_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    temp = {}\n",
        "    temp['cosine_similarity'] = cosine_similarity(np.asarray([lsa_1[i]]), np.asarray([lsa_2[i]]))[0][0]\n",
        "    temp['manhattan_distance'] = euclidean_distances(np.asarray([lsa_1[i]]), np.asarray([lsa_2[i]]))[0][0]\n",
        "    temp['euclidean_distance'] = manhattan_distances(np.asarray([lsa_1[i]]), np.asarray([lsa_2[i]]))[0][0]\n",
        "    distance_and_similarity_scores_3.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jHVZTTRYHe6A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    print(is_duplicate_questions[i], distance_and_similarity_scores_3[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uENvSaywLgrP"
      },
      "cell_type": "markdown",
      "source": [
        "# Word2Vec model(Using Mean to get the sentence vectors)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "n_vSYQP8LN36",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "61vPjXTNB8Ur",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "google_model = KeyedVectors.load_word2vec_format(\"E:\\Models\\pre_trained\\word2vec\\google\\google.300d.bin\", binary=True)\n",
        "#wiki_model = KeyedVectors.load_word2vec_format(\"models/pretrained/glove/wiki/wiki.300d.txt\", binary=False)\n",
        "#common_crawl_model = KeyedVectors.load_word2vec_format(\"models/pretrained/glove/common_crawl/common_crawl.300d.txt\", binary=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tOUcqYwzLzTf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sentence_vectorizer(model, sentence):\n",
        "    vectors =[]\n",
        "    num = 0\n",
        "    for i in sentence.split():\n",
        "        try:\n",
        "            if num == 0:\n",
        "                vectors = model[i]\n",
        "            else:\n",
        "                vectors = np.add(vectors, model[i])\n",
        "            num += 1\n",
        "        except:\n",
        "            pass\n",
        "    return np.array(vectors) / num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xsR-G4WYsu70",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec1 = []\n",
        "for each in sentences_1:\n",
        "    temp = sentence_vectorizer(google_model, each)\n",
        "    if temp.shape[0] != 0:\n",
        "        sent_vec1.append(temp)\n",
        "    else:\n",
        "        sent_vec1.append(np.zeros((300,)))\n",
        "sent_vec1 = np.asarray(sent_vec1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4EsdRpmHGhpM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_vec2 = []\n",
        "for each in sentences_2:\n",
        "    temp = sentence_vectorizer(google_model, each)\n",
        "    if temp.shape[0] != 0:\n",
        "        sent_vec2.append(temp)\n",
        "    else:\n",
        "        sent_vec2.append(np.zeros((300,)))\n",
        "sent_vec2 = np.asarray(sent_vec2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "STeo9-I-He6R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores_4 = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WhWO60WThjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    temp = {}\n",
        "    temp['cosine_similarity'] = cosine_similarity(np.asarray([sent_vec1[i]]), np.asarray([sent_vec2[i]]))[0][0]\n",
        "    temp['manhattan_distance'] = euclidean_distances(np.asarray([sent_vec1[i]]), np.asarray([sent_vec2[i]]))[0][0]\n",
        "    temp['euclidean_distance'] = manhattan_distances(np.asarray([sent_vec1[i]]), np.asarray([sent_vec2[i]]))[0][0]\n",
        "    distance_and_similarity_scores_4.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNWdkvV0Thjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    print(is_duplicate_questions[i], distance_and_similarity_scores_4[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NPFU-WBzThkS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# InferText model"
      ]
    },
    {
      "metadata": {
        "id": "GjDUVOyGThkU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://github.com/facebookresearch/InferSent"
      ]
    },
    {
      "metadata": {
        "id": "6dv_PWSvThkV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from random import randint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "josZK7nlThkw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load Model**"
      ]
    },
    {
      "metadata": {
        "id": "n6zpFS63Thk-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from models.infersent.models import InferSent\n",
        "model_version = 1\n",
        "MODEL_PATH = \"models\\infersent\\infersent%s.pickle\" % model_version\n",
        "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
        "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
        "model = InferSent(params_model)\n",
        "model.load_state_dict(torch.load(MODEL_PATH))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3Ab2lSGThlU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "use_cuda = False\n",
        "model = model.cuda() if use_cuda else model # Keep it on CPU or put it on GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGK1B7e0ThlZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W2V_PATH = 'E:\\Models\\pre_trained\\glove\\commoncrawl\\common_crawl.300d.txt'\n",
        "model.set_w2v_path(W2V_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Wpz7wfJThld",
        "colab_type": "code",
        "outputId": "6252e255-9111-4e78-8859-ca21ed066c1a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.build_vocab_k_words(K=100000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1llZQxTQThme",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Encode Sentences**"
      ]
    },
    {
      "metadata": {
        "id": "p28QtnCsThmi",
        "colab_type": "code",
        "outputId": "d02b0ca6-47e1-4f8d-ef39-c9abd2e23059",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "tW3EZmx8Thm3",
        "colab_type": "code",
        "outputId": "ce05dcb8-0200-4418-f38e-57f9ffec7a9a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_1 = model.encode(sentences_1[:20], bsize=128, tokenize=False, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nb words kept : 139/152 (91.4%)\n",
            "Speed : 25.0 sentences/s (cpu mode, bsize=128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GWaFFXssThnW",
        "colab_type": "code",
        "outputId": "8fb52c07-47ec-46f2-a51f-09a2ff559c75",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_2 = model.encode(sentences_2[:20], bsize=128, tokenize=False, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nb words kept : 140/150 (93.3%)\n",
            "Speed : 35.7 sentences/s (cpu mode, bsize=128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OALLFIe_Thne",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores_6 = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EVMyyBHmThnk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    temp = {}\n",
        "    temp['cosine_similarity'] = cosine_similarity(np.asarray([embeddings_1[i]]), np.asarray([embeddings_2[i]]))[0][0]\n",
        "    temp['manhattan_distance'] = euclidean_distances(np.asarray([embeddings_1[i]]), np.asarray([embeddings_2[i]]))[0][0]\n",
        "    temp['euclidean_distance'] = manhattan_distances(np.asarray([embeddings_1[i]]), np.asarray([embeddings_2[i]]))[0][0]\n",
        "    distance_and_similarity_scores_6.append(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A8t8syvWThoJ",
        "colab_type": "code",
        "outputId": "e3e7d56f-4df3-47d5-a8ca-df7809f0fd3a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "    print(is_duplicate_questions[i], distance_and_similarity_scores_6[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {'cosine_similarity': 0.9458276, 'manhattan_distance': 1.2538241, 'euclidean_distance': 32.184387501109086}\n",
            "0 {'cosine_similarity': 0.6067528, 'manhattan_distance': 2.9255688, 'euclidean_distance': 112.79561321428446}\n",
            "0 {'cosine_similarity': 0.8873254, 'manhattan_distance': 1.8598092, 'euclidean_distance': 72.58798747658739}\n",
            "0 {'cosine_similarity': 0.5393939, 'manhattan_distance': 3.1896555, 'euclidean_distance': 120.62491884012707}\n",
            "0 {'cosine_similarity': 0.75635266, 'manhattan_distance': 3.1802003, 'euclidean_distance': 131.53287864351518}\n",
            "1 {'cosine_similarity': 0.8199016, 'manhattan_distance': 2.2952108, 'euclidean_distance': 86.52014614462496}\n",
            "0 {'cosine_similarity': 0.3553719, 'manhattan_distance': 3.3347626, 'euclidean_distance': 130.02840969695353}\n",
            "1 {'cosine_similarity': 0.96099097, 'manhattan_distance': 0.75167567, 'euclidean_distance': 19.646674617991266}\n",
            "0 {'cosine_similarity': 1.0, 'manhattan_distance': 0.0, 'euclidean_distance': 1.2594475265359506e-05}\n",
            "0 {'cosine_similarity': 0.7971726, 'manhattan_distance': 2.2010882, 'euclidean_distance': 83.40903483864076}\n",
            "0 {'cosine_similarity': 0.59591144, 'manhattan_distance': 3.379172, 'euclidean_distance': 141.06986477379178}\n",
            "1 {'cosine_similarity': 0.9302225, 'manhattan_distance': 1.104042, 'euclidean_distance': 31.58952859152646}\n",
            "1 {'cosine_similarity': 1.0000002, 'manhattan_distance': 0.0, 'euclidean_distance': 4.345100023783743e-06}\n",
            "1 {'cosine_similarity': 0.960274, 'manhattan_distance': 0.72040766, 'euclidean_distance': 17.49958434590917}\n",
            "0 {'cosine_similarity': 0.970024, 'manhattan_distance': 1.1597912, 'euclidean_distance': 27.432081533150267}\n",
            "1 {'cosine_similarity': 0.8476085, 'manhattan_distance': 2.145061, 'euclidean_distance': 87.41615762085985}\n",
            "1 {'cosine_similarity': 1.0000001, 'manhattan_distance': 0.0, 'euclidean_distance': 0.0}\n",
            "0 {'cosine_similarity': 0.8766564, 'manhattan_distance': 1.6476896, 'euclidean_distance': 58.87347629003125}\n",
            "1 {'cosine_similarity': 0.86601734, 'manhattan_distance': 1.7946079, 'euclidean_distance': 64.51746689830156}\n",
            "0 {'cosine_similarity': 0.8747243, 'manhattan_distance': 1.8397535, 'euclidean_distance': 60.018542632348726}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lIkMtICSThoZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Sentence Encoder V2**"
      ]
    },
    {
      "metadata": {
        "id": "aL2-FeJ-Thoa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://tfhub.dev/google/universal-sentence-encoder/2"
      ]
    },
    {
      "metadata": {
        "id": "mb80PEg1Tho2",
        "colab_type": "code",
        "outputId": "94b104c9-9270-4d78-9267-be8ffe64c37f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install --quiet tensorflow-hub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using pip version 18.1, however version 19.0.3 is available.\n",
            "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gsL8BghuThpQ",
        "colab_type": "code",
        "outputId": "24ed8459-b567-4802-c820-9e38b45fd717",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0310 12:42:12.050889  7768 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JXUgrAajThpr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sp_XRgpWThqd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embed = hub.Module(module_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V-jIYTgxThqq",
        "colab_type": "code",
        "outputId": "5cd7f5e6-c1b5-43fa-f137-8ca1cf5f9f61",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "    sentences_embeddings_1 = session.run(embed(sentences_1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0310 13:10:26.869572  7768 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0wKn1UHgThq8",
        "colab_type": "code",
        "outputId": "10403a13-5de9-4604-c472-78ea07cbef75",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as session:\n",
        "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "    sentences_embeddings_2 = session.run(embed(sentences_2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0310 13:10:56.016236  7768 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wD8CGKXQThre",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "distance_and_similarity_scores_8 = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mw2Kb_ohThrs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "USfurja7Thr7",
        "colab_type": "code",
        "outputId": "b97ab105-8e30-4605-9181-6a26430f3eb5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {'cosine_similarity': 0.9486568, 'manhattan_distance': 0.3204472, 'euclidean_distance': 5.245485807812656}\n",
            "0 {'cosine_similarity': 0.6202224, 'manhattan_distance': 0.8715247, 'euclidean_distance': 14.994461547388255}\n",
            "0 {'cosine_similarity': 0.8335015, 'manhattan_distance': 0.57705903, 'euclidean_distance': 9.815707650494005}\n",
            "0 {'cosine_similarity': 0.2900136, 'manhattan_distance': 1.1916263, 'euclidean_distance': 21.74811126565328}\n",
            "0 {'cosine_similarity': 0.49464017, 'manhattan_distance': 1.0053457, 'euclidean_distance': 17.698465278358526}\n",
            "1 {'cosine_similarity': 0.8778694, 'manhattan_distance': 0.49422783, 'euclidean_distance': 7.790173144967412}\n",
            "0 {'cosine_similarity': 0.16489124, 'manhattan_distance': 1.2923691, 'euclidean_distance': 23.196336368258926}\n",
            "1 {'cosine_similarity': 0.9448141, 'manhattan_distance': 0.33222255, 'euclidean_distance': 5.783593213651329}\n",
            "0 {'cosine_similarity': 1.0, 'manhattan_distance': 0.0, 'euclidean_distance': 0.0}\n",
            "0 {'cosine_similarity': 0.83476865, 'manhattan_distance': 0.574859, 'euclidean_distance': 9.804769292395576}\n",
            "0 {'cosine_similarity': 0.12745847, 'manhattan_distance': 1.3210161, 'euclidean_distance': 23.505938380429143}\n",
            "1 {'cosine_similarity': 0.9092075, 'manhattan_distance': 0.42612785, 'euclidean_distance': 7.400624245405197}\n",
            "1 {'cosine_similarity': 1.0, 'manhattan_distance': 0.0, 'euclidean_distance': 0.0}\n",
            "1 {'cosine_similarity': 0.95513123, 'manhattan_distance': 0.29956242, 'euclidean_distance': 5.218573479010956}\n",
            "0 {'cosine_similarity': 0.97338766, 'manhattan_distance': 0.23070462, 'euclidean_distance': 3.2130904488731176}\n",
            "1 {'cosine_similarity': 0.68606377, 'manhattan_distance': 0.7923839, 'euclidean_distance': 13.379268934691936}\n",
            "1 {'cosine_similarity': 1.0000001, 'manhattan_distance': 0.0, 'euclidean_distance': 0.0}\n",
            "0 {'cosine_similarity': 0.810645, 'manhattan_distance': 0.6153944, 'euclidean_distance': 10.599712683309917}\n",
            "1 {'cosine_similarity': 0.8176981, 'manhattan_distance': 0.60382426, 'euclidean_distance': 10.594791327503117}\n",
            "0 {'cosine_similarity': 0.928566, 'manhattan_distance': 0.37797904, 'euclidean_distance': 6.199734789945069}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0REIjwVNThsP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN and TimeDistributed"
      ]
    },
    {
      "metadata": {
        "id": "ZTLQ5ZJNThsQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/zhihang/an-ensemble-approach-cnn-and-timedistributed"
      ]
    },
    {
      "metadata": {
        "id": "zE6jg7HHThsk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YdMktgOMThsx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXelV3HjThtE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime, time, json\n",
        "from string import punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "awzjplbcThtL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gMqAzlFThtO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7264fdb-bcd7-4f97-c4ab-773a1eb442bb"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "TOdeyLYEThtf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import initializers\n",
        "from keras import backend as K\n",
        "from keras.optimizers import SGD\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, Reshape, BatchNormalization, TimeDistributed, Lambda, Activation, LSTM, Flatten, Convolution1D, GRU, MaxPooling1D\n",
        "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DsJUOT3mThtx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_questions = sentences_1.tolist() + sentences_2.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gNE5S8VTht2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_questions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKbzxzKQTht5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "question1_word_sequences = tokenizer.texts_to_sequences(sentences_1.tolist())\n",
        "question2_word_sequences = tokenizer.texts_to_sequences(sentences_2.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjn1esYUThuK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WnTafrvlThuO",
        "colab_type": "code",
        "outputId": "c7f95e95-e73f-4e2c-f37c-f76a527ea6be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_question_len = 0\n",
        "for each in range(length):\n",
        "    max_question_len = max(max_question_len, len(question1_word_sequences[each]), len(question2_word_sequences[each]))\n",
        "print(max_question_len)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i9zDir1ZThuh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_q1 = pad_sequences(question1_word_sequences,\n",
        "                              maxlen = max_question_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0mG5A7_ThvP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_q2 = pad_sequences(question2_word_sequences,\n",
        "                              maxlen = max_question_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bUJJYK2mThvV",
        "colab_type": "code",
        "outputId": "6388266d-5c73-4783-e070-dd510ff7aa1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with open(common_crawl_embeddings, encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split(' ')\n",
        "        word = values[0]\n",
        "        embedding = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = embedding\n",
        "print('Word embeddings:', len(embeddings_index))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word embeddings: 2196016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q1fCQe8jThvz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_dim = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qyRcPN4TThv3",
        "colab_type": "code",
        "outputId": "857f669d-512c-40ca-8bc8-e70b9993c6a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "nb_words = len(word_index)\n",
        "word_embedding_matrix = np.zeros((nb_words + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        word_embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0)) #75,334"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Null word embeddings: 16082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "717pXiF4Thv8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "units = 128 # Number of nodes in the Dense layers\n",
        "dropout = 0.25 # Percentage of nodes to drop\n",
        "nb_filter = 32 # Number of filters to use in Convolution1D\n",
        "filter_length = 3 # Length of filter for Convolution1D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DtvBJ-IbThwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=2)\n",
        "bias = bias_initializer='zeros'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kfX5rFLjThwG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eWwGJL0sThwW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "87678320-eeaf-4fec-ef7b-f9fe22b9b15f"
      },
      "cell_type": "code",
      "source": [
        "model_1_input = Input(shape = (max_question_len,), dtype = 'int32', name = 'model_1_input')\n",
        "model_1_embedding = Embedding(nb_words + 1,\n",
        "                     embedding_dim,\n",
        "                     weights = [word_embedding_matrix], \n",
        "                     input_length = max_question_len,\n",
        "                     trainable = False)(model_1_input)\n",
        "model_1_conv_a = Convolution1D(filters = nb_filter, \n",
        "                         kernel_size = filter_length, \n",
        "                         padding = 'same')(model_1_embedding)\n",
        "model_1_batch_a = BatchNormalization()(model_1_conv_a)\n",
        "model_1_act = Activation('relu')(model_1_batch_a)\n",
        "model_1_drop_a = Dropout(dropout)(model_1_act)\n",
        "model_1_conv_b = Convolution1D(filters = nb_filter, \n",
        "                         kernel_size = filter_length, \n",
        "                         padding = 'same')(model_1_drop_a)\n",
        "model_1_batch_b = BatchNormalization()(model_1_conv_b)\n",
        "model_1_act_b = Activation('relu')(model_1_batch_b)\n",
        "model_1_drop_b = Dropout(dropout)(model_1_act_b)\n",
        "model_1_flat = Flatten()(model_1_drop_b)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RR3kfYpXThwm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_2_input = Input(shape = (max_question_len,), dtype = 'int32', name = 'model_2_input')\n",
        "model_2_embedding = Embedding(nb_words + 1,\n",
        "                     embedding_dim,\n",
        "                     weights = [word_embedding_matrix], \n",
        "                     input_length = max_question_len,\n",
        "                     trainable = False)(model_2_input)\n",
        "model_2_conv_a = Convolution1D(filters = nb_filter, \n",
        "                         kernel_size = filter_length, \n",
        "                         padding = 'same')(model_2_embedding)\n",
        "model_2_batch_a = BatchNormalization()(model_2_conv_a)\n",
        "model_2_act = Activation('relu')(model_2_batch_a)\n",
        "model_2_drop_a = Dropout(dropout)(model_2_act)\n",
        "model_2_conv_b = Convolution1D(filters = nb_filter, \n",
        "                         kernel_size = filter_length, \n",
        "                         padding = 'same')(model_2_drop_a)\n",
        "model_2_batch_b = BatchNormalization()(model_2_conv_b)\n",
        "model_2_act_b = Activation('relu')(model_2_batch_b)\n",
        "model_2_drop_b = Dropout(dropout)(model_2_act_b)\n",
        "model_2_flat = Flatten()(model_2_drop_b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6XGdYsi-Thwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_3_input = Input(shape = (max_question_len,), dtype = 'int32', name = 'model_3_input')\n",
        "model_3_embedding = Embedding(nb_words + 1,\n",
        "                     embedding_dim,\n",
        "                     weights = [word_embedding_matrix],\n",
        "                     input_length = max_question_len,\n",
        "                     trainable = False)(model_3_input)\n",
        "model_3_time_distributed = TimeDistributed(Dense(embedding_dim))(model_3_embedding)\n",
        "model_3_batch = BatchNormalization()(model_3_time_distributed)\n",
        "model_3_act = Activation('relu')(model_3_batch)\n",
        "model_3_drop = Dropout(dropout)(model_3_act)\n",
        "model_3_lambda = Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim, ))(model_3_drop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZTqDf33Thwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_4_input = Input(shape = (max_question_len,), dtype = 'int32', name = 'model_4_input')\n",
        "model_4_embedding = Embedding(nb_words + 1,\n",
        "                     embedding_dim,\n",
        "                     weights = [word_embedding_matrix],\n",
        "                     input_length = max_question_len,\n",
        "                     trainable = False)(model_4_input)\n",
        "model_4_time_distributed = TimeDistributed(Dense(embedding_dim))(model_4_embedding)\n",
        "model_4_batch = BatchNormalization()(model_4_time_distributed)\n",
        "model_4_act = Activation('relu')(model_4_batch)\n",
        "model_4_drop = Dropout(dropout)(model_4_act)\n",
        "model_4_lambda = Lambda(lambda x: K.max(x, axis=1), output_shape=(embedding_dim, ))(model_4_drop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8qzQZ3v0Thw2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wWTYtVWfThw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "merge_layer = concatenate([model_1_flat, model_2_flat, model_3_lambda, model_4_lambda], name = 'merge_layer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nhi18BHpThw_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = Dense(200, activation = 'relu', name = 'dense1')(merge_layer)\n",
        "t = Dropout(0.3)(t)\n",
        "t = BatchNormalization()(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5gJrwBkThxD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = Dense(200, activation = 'relu', name  ='dense2')(t)\n",
        "t = Dropout(0.3)(t)\n",
        "t = BatchNormalization()(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1UqIRnYQThxJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = Dense(100, activation= 'relu',name = 'dense3')(t)\n",
        "t = Dropout(0.3)(t)\n",
        "t = BatchNormalization()(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JJMX7RW6ThxN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_output = Dense(1, activation = 'sigmoid')(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpEImjZlThxQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdB2f-2YThxU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs = [model_1_input, model_2_input, model_3_input, model_4_input], outputs = final_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmThUDHkThxc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7AvSOq0mThxp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_best_weights = 'question_pairs_weights.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8PbDmwHLThxy",
        "colab_type": "code",
        "outputId": "d5f40c68-c15e-40d7-cd81-c520a10c95b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "callbacks = [ModelCheckpoint(save_best_weights, monitor='val_loss', save_best_only=True),\n",
        "             EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')]\n",
        "history = model.fit([train_q1, train_q2, train_q1, train_q2],\n",
        "                    questions.is_duplicate,\n",
        "                    batch_size=256,\n",
        "                    epochs=1, #Use 100, I reduce it for Kaggle,\n",
        "                    validation_split=0.15,\n",
        "                    verbose=True,\n",
        "                    shuffle=True,\n",
        "                    callbacks=callbacks)\n",
        "t1 = time.time()\n",
        "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 343695 samples, validate on 60653 samples\n",
            "Epoch 1/1\n",
            "343695/343695 [==============================] - 126s 367us/step - loss: 0.5500 - acc: 0.7156 - val_loss: 0.4895 - val_acc: 0.7565\n",
            "Minutes elapsed: 2.223541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "thlpSipEThyD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "summary_stats = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
        "                              'train_acc': history.history['acc'],\n",
        "                              'valid_acc': history.history['val_acc'],\n",
        "                              'train_loss': history.history['loss'],\n",
        "                              'valid_loss': history.history['val_loss']})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RIxZsGW1ThyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "ef115c6a-476f-4ddf-e223-aa5df380df83"
      },
      "cell_type": "code",
      "source": [
        "summary_stats"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_acc</th>\n",
              "      <th>valid_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.71562</td>\n",
              "      <td>0.550006</td>\n",
              "      <td>0.756517</td>\n",
              "      <td>0.489547</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  train_acc  train_loss  valid_acc  valid_loss\n",
              "0      1    0.71562    0.550006   0.756517    0.489547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "ULNZPQWZThyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "bbee048d-fd08-4957-8b5a-75d71ed7fc39"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(summary_stats.train_loss) # blue\n",
        "plt.plot(summary_stats.valid_loss) # green\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYYgzAACG+R/ehAOZUzCTLgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "VNln5hIvThyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "326c6a2f-0777-4515-bd69-86a16f3a8c7d"
      },
      "cell_type": "code",
      "source": [
        "min_loss, idx = min((loss, idx) for (idx, loss) in enumerate(history.history['val_loss']))\n",
        "print('Minimum loss at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(min_loss))\n",
        "min_loss = round(min_loss, 4)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum loss at epoch 1 = 0.4895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kYsJiuRnThyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(save_best_weights)\n",
        "predictions = model.predict([test_q1, test_q2, test_q1, test_q2], verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "erbL7Um_Fa6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del embeddings_index\n",
        "del embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BizDAv4UFlgs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ph72DaWGFtDD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del train_q1\n",
        "del train_q2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bnp7U-ERHTq6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del word_embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_VQCmb6HhoX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del question1_word_sequences\n",
        "del question2_word_sequences\n",
        "del all_questions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "elQTFbMuHhgN"
      },
      "cell_type": "markdown",
      "source": [
        "**Siamese Neural Networks(Using LSTM and GRU)**"
      ]
    },
    {
      "metadata": {
        "id": "a1ln-4sTThyx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://medium.com/mlreview/implementing-malstm-on-kaggles-quora-question-pairs-competition-8b31b0b16a07"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dE_9Xb7uHqgw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "import keras.backend as backend\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda, GRU, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DWJ7T5-xThy_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocabulary = dict()\n",
        "inverse_vocabulary = ['<unk>']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lDqBuGauThzJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q2n_left = []\n",
        "for sentence in sentences_1.tolist():\n",
        "    temp_sentence = []\n",
        "    for word in sentence.split():\n",
        "        if word not in vocabulary:\n",
        "            vocabulary[word] = len(inverse_vocabulary)\n",
        "            temp_sentence.append(len(inverse_vocabulary))\n",
        "            inverse_vocabulary.append(word)\n",
        "        else:\n",
        "            temp_sentence.append(vocabulary[word])\n",
        "    q2n_left.append(temp_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TUOuLqh0ThzV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q2n_right = []\n",
        "for sentence in sentences_2.tolist():\n",
        "    temp_sentence = []\n",
        "    for word in sentence.split():\n",
        "        if word not in vocabulary:\n",
        "            vocabulary[word] = len(inverse_vocabulary)\n",
        "            temp_sentence.append(len(inverse_vocabulary))\n",
        "            inverse_vocabulary.append(word)\n",
        "        else:\n",
        "            temp_sentence.append(vocabulary[word])\n",
        "    q2n_right.append(temp_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d12cT2W6Thzh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "embeddings = np.zeros((len(vocabulary) + 1, embedding_dim))\n",
        "embeddings[0] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m335l-nAGoh-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UhtUrY3AGBCI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "google_model = KeyedVectors.load_word2vec_format(google_embeddings, binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgJE5IG_Thz1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for word, index in vocabulary.items():\n",
        "    if word in google_model.vocab:\n",
        "        embeddings[index] = google_model.word_vec(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yylXEJPThz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del google_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpjEmyWSTh0H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6cdNIb5rTh0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_left = q2n_left"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c6xYqZ0CTh0O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_right = q2n_right"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nx1ohcwUTh0Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82e15527-b426-46d9-fb94-c0df6b85a021"
      },
      "cell_type": "code",
      "source": [
        "max_seq_length = 0\n",
        "for each in range(length):\n",
        "    max_seq_length = max(max_seq_length, len(q2n_left[each]), len(q2n_right[each]))\n",
        "print(max_seq_length)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a0A4__Z7Th0m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_left = pad_sequences(q2n_left, maxlen=max_seq_length)\n",
        "dataset_right = pad_sequences(q2n_right, maxlen=max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0tRbrmVTh0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5993442f-ace2-416f-de67-58e9441ff2c1"
      },
      "cell_type": "code",
      "source": [
        "dataset_left.shape == dataset_right.shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "mv21EhXoTh1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_hidden1 = 512\n",
        "n_hidden2 = 384\n",
        "n_hidden3 = 256\n",
        "n_hidden4 = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WljRtYIvJcTn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "left_input = Input(shape=(max_seq_length, ), dtype='int32')\n",
        "right_input = Input(shape=(max_seq_length, ), dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ksWe8MukKbxW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], \n",
        "                            input_length=max_seq_length, trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "U0jTBGv4Kck8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded_left = embedding_layer(left_input)\n",
        "encoded_right = embedding_layer(right_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5e9B1ChNKgA3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shared_lstm1 = LSTM(n_hidden1, return_sequences=True)\n",
        "shared_dropout1 = Dropout(0.3)\n",
        "shared_gru1 = GRU(n_hidden2, return_sequences=True)\n",
        "shared_dropout2 = Dropout(0.4)\n",
        "shared_gru2 = GRU(n_hidden3, return_sequences=True)\n",
        "shared_dropout3 = Dropout(0.3)\n",
        "shared_lstm2 = LSTM(n_hidden4, return_sequences=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oiSpiz9uLGu3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "left_lstm1 = shared_lstm1(encoded_left)\n",
        "left_dropout1 = shared_dropout1(left_lstm1)\n",
        "left_gru1 = shared_gru1(left_dropout1)\n",
        "left_dropout2 = shared_dropout2(left_gru1)\n",
        "left_gru2 = shared_gru2(left_dropout2)\n",
        "left_dropout3 = shared_dropout3(left_gru2)\n",
        "left_lstm2 = shared_lstm2(left_dropout3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bcQJfYn6Ma5S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "right_lstm1 = shared_lstm1(encoded_right)\n",
        "right_dropout1 = shared_dropout1(right_lstm1)\n",
        "right_gru1 = shared_gru1(right_dropout1)\n",
        "right_dropout2 = shared_dropout2(right_gru1)\n",
        "right_gru2 = shared_gru2(right_dropout2)\n",
        "right_dropout3 = shared_dropout3(right_gru2)\n",
        "right_lstm2 = shared_lstm2(right_dropout3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ug1R5gTGM4oR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "manhattan_distance_for_lstm = Lambda(function=lambda x: backend.exp(-backend.sum(backend.abs(x[0]-x[1]), axis=1, keepdims=True)),\n",
        "                                     output_shape=lambda x: (x[0][0], 1))([left_lstm2, right_lstm2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "n5TGTK2CUrN8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a31d7321-4ac4-4a1e-f1ee-9f240a331357"
      },
      "cell_type": "code",
      "source": [
        "siamese_network = Model([left_input, right_input], manhattan_distance_for_lstm)\n",
        "siamese_network.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=['accuracy'])\n",
        "siamese_network.fit([dataset_left, dataset_right], is_duplicate_questions, batch_size=256, \n",
        "                        epochs=1)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "404348/404348 [==============================] - 3060s 8ms/step - loss: 0.1753 - acc: 0.7357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2de92455f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "w2i2SErFIcrS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "siamese_network.save_weights(\"siamese_network_quora_len_97.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pjbDZAtTKrX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "66087653-6f88-47a2-b8e5-10b7573b8e1f"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('siamese_network_quora_len_97.h5')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 52056, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 800, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vE3vQkKjX5Fe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pg4sHXuxXdOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h5file = h5py.File('siamese_network_quora_len_97.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oytgyy-eYs6M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "json = siamese_network.to_json()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3SL6IPQoY5XD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"siamese_network_quora_len_97.json\", \"w\") as json_file:\n",
        "    json_file.write(json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RwglWk8QLtcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "1f241905-c355-44bd-fe6d-0c7a1e8c881e"
      },
      "cell_type": "code",
      "source": [
        "uploaded = drive.CreateFile({'title': 'siamese_network_quora_len_97.json'})\n",
        "uploaded.SetContentString(h5file)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-75e7199162f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'siamese_network_quora_len_97.h5'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetContentString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUpload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Uploaded file with ID {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mSetContentString\u001b[0;34m(self, content, encoding)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \"\"\"\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mimeType'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mimeType'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'text/plain'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'File' object has no attribute 'encode'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zHCPwExmYD_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}